{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detailed Analysis of Results for Bound Vanish Synthetic Data Generated from a Single Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import red\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle as pkl\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from matplotlib.axes import Axes\n",
    "from matplotlib.figure import Figure\n",
    "from matplotlib import gridspec\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "colors = sns.color_palette('colorblind')\n",
    "\n",
    "def get_subplots(systems: list[str], scale_x: float = 1, scale_y: float =1) -> tuple[plt.Figure, list[plt.Axes]]:\n",
    "    # Plot two columns side-by-side\n",
    "    n_cols = min(2, len(systems))\n",
    "    n_rows = int(np.ceil(len(systems) / n_cols))\n",
    "    # fig, axs = plt.subplots(n_rows, n_cols, figsize=(3 * n_cols, 5*n_rows))\n",
    "    fig, axs = plt.subplots(n_rows, n_cols, figsize=(scale_x*3 * n_cols, scale_y*3*n_rows))\n",
    "    if len(systems) == 1:\n",
    "        axs = [axs]\n",
    "    else:\n",
    "        axs = axs.flatten()\n",
    "\n",
    "    # Set titles\n",
    "    for i, system in enumerate(systems):\n",
    "        axs[i].set_title(system)\n",
    "\n",
    "    # Remove any unused axes\n",
    "    for i in range(len(systems), len(axs)):\n",
    "        fig.delaxes(axs[i])\n",
    "\n",
    "    return fig, axs\n",
    "\n",
    "def sanitise_name(name: str) -> str:\n",
    "    # Replace underscores with spaces\n",
    "    name = name.replace('_', ' ')\n",
    "    \n",
    "    # Split the string by spaces and newlines\n",
    "    words = name.split()\n",
    "    \n",
    "    # Capitalize the first letter of each word\n",
    "    capitalized_words = [word[0].upper() + word[1:] if word else '' for word in words]\n",
    "    \n",
    "    # Join the words back together with spaces\n",
    "    sanitized_name = ' '.join(capitalized_words)\n",
    "    \n",
    "    # Restore newlines\n",
    "    sanitized_name = sanitized_name.replace(' \\n ', '\\n')\n",
    "    \n",
    "    return sanitized_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../compute_equil_times/output_single/synthetic_data_bound_vanish_with_equil_times.pkl\", \"rb\") as f:\n",
    "    data = pkl.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and process data <a id=\"load\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../compute_equil_times/output_single/synthetic_data_bound_vanish_with_equil_times.pkl\", \"rb\") as f:\n",
    "    data = pkl.load(f)\n",
    "\n",
    "datasets = list(data.keys())\n",
    "# Sort datasets to put standard first\n",
    "datasets = sorted(datasets, key=lambda x: x != \"standard\")\n",
    "systems = [system for system in data[datasets[0]].keys() if system != \"times\"]\n",
    "methods = [method for method in data[datasets[0]][systems[0]][0].keys() if method != \"data\"]\n",
    "\n",
    "# Create version of the data with MIF only\n",
    "mif_data = {dataset: data[dataset][\"MIF\"] for dataset in datasets}\n",
    "\n",
    "# Seperate out automated and fixed methods\n",
    "automated_methods = [method for method in methods if \"Discard\" not in method]\n",
    "fixed_methods = [method for method in methods if \"Discard\" in method]\n",
    "\n",
    "def bootstrap(data: np.ndarray, fn: callable = lambda x: x, n_bootstraps: int = 10_000) -> tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"Get the 95 % confidence interval for the mean\"\"\"\n",
    "    means = np.zeros(n_bootstraps)\n",
    "    for i in range(n_bootstraps):\n",
    "        # Get a random list of indices\n",
    "        values = np.random.choice(data, size=len(data), replace=True)\n",
    "        # Apply passed function to the data\n",
    "        values = fn(values)\n",
    "        # Take mean. If fn has already been applied to give a single value,\n",
    "        # e.g. the variance, then this will not change the value.\n",
    "        means[i] = np.mean(values)\n",
    "    return np.percentile(means, [2.5, 97.5]), means\n",
    "\n",
    "# Skip slow bootstrap calculations if FIGURES_ONLY is set\n",
    "if not os.environ.get(\"FIGURES_ONLY\", False):\n",
    "\n",
    "    # Compute statistics for all datasets.\n",
    "    overall_results = {}\n",
    "    distributions = {}\n",
    "\n",
    "    # Can't pickle lambda functions for multiprocessing, so define the functions here\n",
    "\n",
    "    for dataset in tqdm(datasets):\n",
    "        overall_results[dataset] = {}\n",
    "        distributions[dataset] = {}\n",
    "        for system in systems:\n",
    "            overall_results[dataset][system] = {}\n",
    "            distributions[dataset][system] = {}\n",
    "\n",
    "            for method in methods:\n",
    "                overall_results[dataset][system][method] = {}\n",
    "                distributions[dataset][system][method] = {}\n",
    "                local_data = {i: data[dataset][system][i][method] for i in data[dataset][system]}\n",
    "\n",
    "                # Basic stats\n",
    "                means = np.array([local_data[i][\"mean\"] for i in local_data])\n",
    "                bias = means.mean()\n",
    "                variance = means.var()\n",
    "\n",
    "                # MUEs and RMSEs are easy to calculate as the true answer is 0\n",
    "                mues = abs(means)\n",
    "                mue = mues.mean()\n",
    "                mses = means ** 2\n",
    "                rmse = np.sqrt(mses.mean())\n",
    "\n",
    "                # Check time taken for the calculations\n",
    "                times = np.array([local_data[i][\"time\"] for i in local_data])\n",
    "                time = times.mean()\n",
    "\n",
    "                # Fraction of data discarded\n",
    "                fracs = np.array([local_data[i][\"frac_discarded\"] for i in local_data])\n",
    "                frac_discarded = fracs.mean()\n",
    "\n",
    "                # Get the 95 % confidence intervals\n",
    "                mean_ci, mean_distr = bootstrap(means)\n",
    "                frac_ci, frac_distr = bootstrap(fracs)\n",
    "                time_ci, time_distr = bootstrap(times)\n",
    "                var_ci, var_distr = bootstrap(means, np.var)\n",
    "                mue_ci, mue_distr = bootstrap(means, abs)\n",
    "                # CIs for the RMSE - need to square root to get the RMSE\n",
    "                rmse_ci, rmse_distr = bootstrap(means, np.square)\n",
    "                rmse_ci = np.sqrt(rmse_ci)\n",
    "                rmse_distr = np.sqrt(rmse_distr)\n",
    "\n",
    "                # Save the results\n",
    "                overall_results[dataset][system][method][\"bias\"] = bias\n",
    "                overall_results[dataset][system][method][\"variance\"] = variance\n",
    "                overall_results[dataset][system][method][\"mue\"] = mue\n",
    "                overall_results[dataset][system][method][\"rmse\"] = rmse\n",
    "                overall_results[dataset][system][method][\"time\"] = time\n",
    "                overall_results[dataset][system][method][\"frac_discarded\"] = frac_discarded\n",
    "                overall_results[dataset][system][method][\"mean_ci\"] = mean_ci\n",
    "                overall_results[dataset][system][method][\"frac_ci\"] = frac_ci\n",
    "                overall_results[dataset][system][method][\"time_ci\"] = time_ci\n",
    "                overall_results[dataset][system][method][\"var_ci\"] = var_ci\n",
    "                overall_results[dataset][system][method][\"mue_ci\"] = mue_ci\n",
    "                overall_results[dataset][system][method][\"rmse_ci\"] = rmse_ci\n",
    "\n",
    "                # Save the distributions\n",
    "                distributions[dataset][system][method][\"means\"] = means\n",
    "                distributions[dataset][system][method][\"fracs\"] = fracs\n",
    "                distributions[dataset][system][method][\"times\"] = times\n",
    "                distributions[dataset][system][method][\"mues\"] = mues\n",
    "                distributions[dataset][system][method][\"mses\"] = mses\n",
    "\n",
    "                # Save the bootstrap distributions\n",
    "                distributions[dataset][system][method][\"mean_boot\"] = mean_distr\n",
    "                distributions[dataset][system][method][\"frac_boot\"] = frac_distr\n",
    "                distributions[dataset][system][method][\"time_boot\"] = time_distr\n",
    "                distributions[dataset][system][method][\"var_boot\"] = var_distr\n",
    "                distributions[dataset][system][method][\"mue_boot\"] = mue_distr\n",
    "                distributions[dataset][system][method][\"rmse_boot\"] = rmse_distr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.environ.get(\"FIGURES_ONLY\", False):\n",
    "    with open(\"output_single/overall_results.pkl\", \"rb\") as f:\n",
    "        overall_results = pkl.load(f)\n",
    "\n",
    "    with open(\"output_single/distributions.pkl\", \"rb\") as f:\n",
    "        distributions = pkl.load(f)\n",
    "\n",
    "else:\n",
    "    with open(\"output_single/overall_results.pkl\", \"wb\") as f:\n",
    "        pkl.dump(overall_results, f)\n",
    "\n",
    "    with open(\"output_single/distributions.pkl\", \"wb\") as f:\n",
    "        pkl.dump(distributions, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect the RMSEs into dataframes. We'll create one table for each dataset.\n",
    "\n",
    "for dataset in datasets:\n",
    "    # Save a latex table of results\n",
    "    rows = []\n",
    "    for method in automated_methods:\n",
    "        system_rmses = {}\n",
    "        for system in systems:\n",
    "            rmse = overall_results[dataset][system][method][\"rmse\"]\n",
    "            upper_ci = overall_results[dataset][system][method][\"rmse_ci\"][1]\n",
    "            lower_ci = overall_results[dataset][system][method][\"rmse_ci\"][0]\n",
    "            system_rmses[system] = f\"${rmse:.2f}_{{{lower_ci:.2f}}}^{{{upper_ci:.2f}}}$\"\n",
    "        row = {\"Method\": method, **system_rmses}\n",
    "        rows.append(row)\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    df.to_latex(f\"output_single/rmse_table_{dataset}.tex\", index=False, escape=False, column_format= \"l\" + \"c\" * len(systems))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data Creation Parameters and Plot Bias, SEM and RMSE <a id=\"plot\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../synthetic_data_creation/output_single/synthetic_data_params.pkl\", \"rb\") as f:\n",
    "    params = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exp_decay(x: np.ndarray, a: float, b: float) -> np.ndarray:\n",
    "    return a * np.exp(-b * x)\n",
    "\n",
    "def compute_bias(times: np.ndarray,\n",
    "                 exp_params: tuple[float, float],\n",
    "                 fast_exp_params: tuple[float, float]) -> np.ndarray:\n",
    "    \"\"\"Compute the bias for the given times\"\"\"\n",
    "    # First, compute the bias at each point in the series\n",
    "    bias = exp_decay(times, *exp_params) + exp_decay(times, *fast_exp_params)\n",
    "    # Then, for each data point, average over all subsequent data points to get the mean biases\n",
    "    mean_bias = np.zeros(len(bias))\n",
    "    for i, _ in enumerate(bias):\n",
    "        n_points = len(bias) - i\n",
    "        mean_bias[i] = np.sum(bias[i:]) / n_points    \n",
    "\n",
    "    return mean_bias\n",
    "\n",
    "def compute_mean_variance(times: np.ndarray,\n",
    "                          autocov_series: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Compute the mean variance over the times passed.\"\"\"\n",
    "    # Precompute cumulative sums\n",
    "    # return autocov_series[0] + 2*np.sum(autocov_series[1:])\n",
    "    cumsum_autocov = np.cumsum(autocov_series[1:])\n",
    "    uncor_variance = autocov_series[0]\n",
    "\n",
    "    forward_cor_variances = np.zeros(len(times))\n",
    "    for i in range(len(times)):\n",
    "        remaining_points = len(times) - i\n",
    "        forward_cor_variances[i] = cumsum_autocov[remaining_points - 1] if remaining_points - 1 < len(cumsum_autocov) else cumsum_autocov[-1]\n",
    "\n",
    "    # Backward correlations are just the same as forward correlations, but in reverse,\n",
    "    # so simply double and add uncorrelated variance\n",
    "    return np.mean(2*forward_cor_variances + uncor_variance)\n",
    "\n",
    "def compute_sem(times: np.ndarray,\n",
    "                autocov_series: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Compute the standard error of the mean for the given times. It is assumed\n",
    "    that the times passed represent the entire series, with same frequency as the \n",
    "    original data.\n",
    "    \"\"\"\n",
    "    sems = np.zeros(len(times))\n",
    "    for i, _ in tqdm(enumerate(times), total=len(times), desc=\"Processing Times\"):\n",
    "        variance = compute_mean_variance(times[i:], autocov_series)\n",
    "        n_points = len(times) - i\n",
    "        sems[i] = np.sqrt(variance / n_points)\n",
    "    return sems\n",
    "\n",
    "def compute_rmse(times: np.ndarray,\n",
    "                 exp_params: tuple[float, float],\n",
    "                 fast_exp_params: tuple[float, float],\n",
    "                 autocov_series: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Compute the RMSE at each time given the exponential parameters. It is\n",
    "    assumed that the times passed represent the entire series, and the number of\n",
    "    data points are the same as those sampled originally.\n",
    "    \"\"\"\n",
    "    bias = compute_bias(times, exp_params, fast_exp_params)\n",
    "    sem = compute_sem(times, autocov_series)\n",
    "    return np.sqrt(sem ** 2 + bias ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skip slow calculations if FIGURES_ONLY is set\n",
    "if not os.environ.get(\"FIGURES_ONLY\", False):\n",
    "\n",
    "    # Calculate the bias, SEM, and RMSE for each dataset\n",
    "    fixed_trunc_error_series = {}\n",
    "\n",
    "    # Currently, only compute for the standard results\n",
    "    for dataset in datasets:\n",
    "        fixed_trunc_error_series[dataset] = {}\n",
    "        for system in systems:\n",
    "            fixed_trunc_error_series[dataset][system] = {}\n",
    "\n",
    "            # Get the parameters used to generate the series\n",
    "            exp_params = params[system][\"exp_params\"]\n",
    "            fast_exp_params = params[system][\"fast_exp_params\"]\n",
    "            variance_fac = 1 if dataset != \"noisy\" else 5\n",
    "            autocov_series = params[system][\"autocov_convex\"] * variance_fac\n",
    "\n",
    "            # If this is the subsampled dataset, them subsample the autocovariance series to account for this\n",
    "            autocov_series = autocov_series[::100] if dataset == \"subsampled\" else autocov_series\n",
    "\n",
    "            # If the dataset is block averaged, the stats are the same as the standard dataset\n",
    "            # If dataset is subsampled, we'll just subsample the standard times.\n",
    "            dataset_lookup = dataset if dataset not in [\"block_averaged\", \"subsampled\"] else \"standard\"\n",
    "            test_data = data[dataset_lookup][system][0][\"data\"]\n",
    "            tot_time = 8 if dataset != \"short\" else 0.2\n",
    "            delta_t = 0.0008 # 200 steps energy frequency times 4 fs per step\n",
    "            # First datum is at 0.8 ps, and last datum is at tot_time - 0.8 ps due to the way the data were generated\n",
    "            times = np.linspace(delta_t, tot_time-delta_t, len(test_data)) # The times at which the data were sampled\n",
    "            if dataset == \"subsampled\":\n",
    "                times = times[::100]\n",
    "\n",
    "            # Compute the bias, sem, and rmse\n",
    "            bias = compute_bias(times, exp_params, fast_exp_params)\n",
    "            sem = compute_sem(times, autocov_series)\n",
    "            rmse = np.sqrt(sem ** 2 + bias ** 2)\n",
    "\n",
    "            # Get the optimal truncation point\n",
    "            trunc_point = np.argmin(rmse)\n",
    "            trunc_time = times[trunc_point]\n",
    "\n",
    "            # If this is block averaged data, then we need to downsample the series\n",
    "            if dataset == \"block_averaged\":\n",
    "                # Blocks of size 100. This is an approximate way of doing things, but only\n",
    "                # slightly affects points at very start/ end\n",
    "                trunc_point = (bias.shape[0] // 100)*100\n",
    "                bias = np.sqrt(np.mean(bias[:trunc_point].reshape(-1, 100)**2, axis=1))\n",
    "                sem = np.sqrt(np.mean(sem[:trunc_point].reshape(-1, 100)**2, axis=1))\n",
    "                rmse = np.sqrt(np.mean(rmse[:trunc_point].reshape(-1, 100)**2, axis=1))\n",
    "            \n",
    "            assert len(sem) == len(data[dataset][system][0][\"data\"]), f\"Length of SEM series {len(sem)} does not match length of data {len(data[dataset][system][0]['data'])}\"\n",
    "\n",
    "            # Save the results\n",
    "            fixed_trunc_error_series[dataset][system][\"bias_series\"] = bias\n",
    "            fixed_trunc_error_series[dataset][system][\"sem_series\"] = sem\n",
    "            fixed_trunc_error_series[dataset][system][\"rmse_series\"] = rmse\n",
    "            fixed_trunc_error_series[dataset][system][\"optimal_trunc_point\"] = trunc_point\n",
    "            fixed_trunc_error_series[dataset][system][\"optimal_trunc_time\"] = trunc_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.environ.get(\"FIGURES_ONLY\", False):\n",
    "    with open(\"output_single/fixed_trunc_error_series_stats.pkl\", \"rb\") as f:\n",
    "        fixed_trunc_error_series = pkl.load(f)\n",
    "else:\n",
    "    with open(\"output_single/fixed_trunc_error_series_stats.pkl\", \"wb\") as f:\n",
    "        pkl.dump(fixed_trunc_error_series, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_theoretical_rmse_on_axis(ax: Axes, dataset: str, system: str) -> None:\n",
    "    lookup_dataset = dataset if dataset not in [\"block_averaged\", \"subsampled\"] else \"standard\"\n",
    "    test_data = data[lookup_dataset][system][0][\"data\"]\n",
    "    tot_time = 8 if dataset != \"short\" else 0.2\n",
    "    # test_times = np.linspace(0, tot_time, len(test_data) + 1)[1:] # The times at which the data were sampled\n",
    "    delta_t = 0.0008 # 200 steps energy frequency times 4 fs per step\n",
    "    test_times = np.linspace(delta_t, tot_time-delta_t, len(test_data)) # The times at which the data were sampled\n",
    "    if dataset == \"subsampled\":\n",
    "        test_times = test_times[::100]\n",
    "    if dataset == \"block_averaged\":\n",
    "        trunc_point = (len(test_times) // 100)*100\n",
    "        test_times = test_times[:trunc_point][49::100]\n",
    "    rmse_series = fixed_trunc_error_series[dataset][system][\"rmse_series\"]\n",
    "\n",
    "    # Get the real RMSE from the discarded fractions\n",
    "    real_rmse = [overall_results[dataset][system][method][\"rmse\"] for method in fixed_methods]\n",
    "    real_cis = [overall_results[dataset][system][method][\"rmse_ci\"] for method in fixed_methods]\n",
    "    cis_lower = abs(np.array(real_cis)[:,0] - np.array(real_rmse))\n",
    "    cis_upper = abs(np.array(real_cis)[:,1] - np.array(real_rmse))\n",
    "    fracs = [float(method.split(\" \")[-1]) for method in fixed_methods]\n",
    "    tot_time = 8 - delta_t if dataset != \"short\" else 0.2 - delta_t\n",
    "    times = [(frac * tot_time)+delta_t for frac in fracs]\n",
    "\n",
    "    # Plot the RMSE\n",
    "    ax.plot(test_times[:], rmse_series[:], label=\"Theoretical\", zorder=2, alpha=0.7)\n",
    "    ax.errorbar(times, real_rmse, yerr=[cis_lower, cis_upper], fmt='-', label=\"Empirical\", zorder=1, ecolor='black')\n",
    "    ax.set_xlabel(\"Truncation Time / ns\")\n",
    "    ax.set_ylabel(\"$\\\\mathrm{RMSE}(\\\\langle \\\\Delta G \\\\rangle_{[n_{0},N]})$ / kcal mol$^{-1}$\")\n",
    "    ax.set_title(system)\n",
    "    \n",
    "    # Set max y limit to be 10 % above the highest RMSE, and 10 % below the lowest RMSE\n",
    "    threshold =np.min(real_rmse[:-1]) * 0.9, np.max(real_rmse[:-1]) * 1.1\n",
    "    ax.set_ylim(*threshold)\n",
    "\n",
    "fig, axs = get_subplots(systems)\n",
    "\n",
    "for i, system in enumerate(systems):\n",
    "    plot_theoretical_rmse_on_axis(axs[i], \"standard\", system)\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "# Only put the legend to the left of the last plot\n",
    "axs[-2].legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "fig.savefig(\"output_single/theoretical_vs_empirical_rmse.png\", dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_error_components_on_ax(ax: Axes, dataset: str, system: str, show_min: bool = True) -> None:\n",
    "    test_data = data[dataset][system][0][\"data\"]\n",
    "    tot_time = 8 if dataset != \"short\" else 0.2\n",
    "    test_times = np.linspace(0, tot_time, len(test_data) + 1)[1:] # The times at which the data was sampled\n",
    "    bias_series = fixed_trunc_error_series[dataset][system][\"bias_series\"]\n",
    "    sem_series = fixed_trunc_error_series[dataset][system][\"sem_series\"]\n",
    "    rmse_series = fixed_trunc_error_series[dataset][system][\"rmse_series\"]\n",
    "\n",
    "    # Plot the error components, truncating the last 1 % of the data\n",
    "    n_truncate = round(len(test_times) * 0.01) # Truncate the last 1 % of the data to avoid large RMSE scaling the y-axis\n",
    "    ax.plot(test_times[:-(n_truncate + 1)], rmse_series[:-(n_truncate+1)], label=\"$\\\\mathrm{RMSE}(\\\\langle \\\\Delta G \\\\rangle_{[n_{0},N]})$\", zorder=2, alpha=0.7)\n",
    "    ax.plot(test_times[:-(n_truncate + 1)], bias_series[:-(n_truncate+1)], label=\"$\\\\mathrm{Bias}(\\\\langle \\\\Delta G \\\\rangle_{[n_{0},N]})$\", zorder=1, alpha=0.7)\n",
    "    ax.plot(test_times[:-(n_truncate + 1)], sem_series[:-(n_truncate +1)], label=\"$\\\\mathrm{SD}(\\\\langle \\\\Delta G \\\\rangle_{[n_{0},N]})$\", zorder=1, alpha=0.7)\n",
    "    \n",
    "    if show_min:\n",
    "        # Plot dashed vertical line at the optimal truncation point\n",
    "        trunc_time = fixed_trunc_error_series[dataset][system][\"optimal_trunc_time\"]\n",
    "        ax.axvline(trunc_time, color='black', linestyle='--', label=\"Optimal Truncation Time\")\n",
    "\n",
    "        # Plot a dashed horizontal line at the RMSE at the optimal truncation point\n",
    "        trunc_rmse = rmse_series[np.argmin(rmse_series)]\n",
    "        ax.axhline(trunc_rmse, color='black', linestyle='--')\n",
    "\n",
    "        # Add a small red dot at the minimum RMSE\n",
    "        ax.plot(trunc_time, trunc_rmse, 'ro', alpha=0.7)\n",
    "\n",
    "    ax.set_xlabel(\"Truncation Time / ns\")\n",
    "    ax.set_ylabel(\"Error / kcal mol$^{-1}$\")\n",
    "    ax.set_title(system)\n",
    "\n",
    "# Plot the components of the RMSE\n",
    "fig, axs = get_subplots(systems)\n",
    "\n",
    "for i, system in enumerate(systems):\n",
    "    ax = axs[i]\n",
    "    plot_error_components_on_ax(ax, \"standard\", system, show_min=False)\n",
    "    ax.set_xlabel(\"Truncation Time / ns\")\n",
    "    ax.set_ylabel(\"Error / kcal mol$^{-1}$\")\n",
    "    ax.set_title(system)\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "# Only put the legend to the left of the last plot\n",
    "axs[-2].legend(bbox_to_anchor=(1.2, 0.7), loc='upper left')\n",
    "\n",
    "fig.savefig(\"output_single/error_components.png\", dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Discard Times\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_discard_times_on_ax(ax: Axes, dataset: str, system: str, n_truncate: int = 100) -> None:\n",
    "    # Get a dataframe of the times discarded\n",
    "    tot_time = 8 if dataset != \"short\" else 0.2\n",
    "    df_times = pd.DataFrame({method: distributions[dataset][system][method][\"fracs\"]*tot_time for method in automated_methods})\n",
    "    sns.violinplot(data=df_times, ax=ax, orient=\"h\",palette=colors, alpha=1)\n",
    "    ax.set_title(system)\n",
    "    ax.set_xlabel(\"Truncation Time / ns\")\n",
    "\n",
    "    # Plot dashed vertical line at the optimal truncation point\n",
    "    trunc_time = fixed_trunc_error_series[dataset][system][\"optimal_trunc_time\"]\n",
    "    ax.axvline(trunc_time, color='black', linestyle='--', label=\"Optimal Truncation Time\")\n",
    "\n",
    "    ax.set_title(system)\n",
    "\n",
    "# Plot the discard times\n",
    "fig, axs = get_subplots(systems)\n",
    "\n",
    "for i, system in enumerate(systems):\n",
    "    ax = axs[i]\n",
    "    plot_discard_times_on_ax(ax, \"standard\", system, 100)\n",
    "    # Remove y tick labels from right hand column\n",
    "    if i % 2 == 1:\n",
    "        ax.set_yticklabels([])\n",
    "    ax.set_xlabel(\"Truncation Time / ns\")\n",
    "    ax.set_title(system)\n",
    "\n",
    "# Tight layout, but only in the y direction\n",
    "fig.subplots_adjust(hspace=0.5)\n",
    "\n",
    "# Only put the legend to the left of the last plot\n",
    "axs[-2].legend(bbox_to_anchor=(1.2, 0.7), loc='upper left')\n",
    "\n",
    "fig.savefig(\"output_single/discard_times_standard.png\", dpi=300, bbox_inches='tight')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot RMSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_rmses_on_ax(ax: Axes, dataset: str, system: str, n_truncate: int = 100) -> None:\n",
    "    # Get RMSEs and confidence intervals\n",
    "    rmse = [overall_results[dataset][system][method][\"rmse\"] for method in automated_methods]\n",
    "    cis = [overall_results[dataset][system][method][\"rmse_ci\"] for method in automated_methods]\n",
    "\n",
    "    # Convert CIs from absolute values to relative values\n",
    "    cis_lower = np.array(rmse) - np.array(cis)[:,0]\n",
    "    cis_upper = np.array(cis)[:,1] - np.array(rmse)\n",
    "    error_bar_settings = {\"capsize\": 0, \"alpha\": 1, \"elinewidth\": 1}\n",
    "    ax.bar(automated_methods, rmse, yerr=[cis_lower, cis_upper], capsize=5, \n",
    "           alpha=1, error_kw=error_bar_settings, color=colors, edgecolor='black', linewidth=1)\n",
    "    \n",
    "    # Get the minimum possible fixed-time RMSE and plot a horizontal to show it\n",
    "    min_rmse = np.min(fixed_trunc_error_series[dataset][system][\"rmse_series\"])\n",
    "    ax.axhline(min_rmse, color='black', linestyle='--', label=\"Minimum Fixed-Time RMSE\")\n",
    "\n",
    "    # Plot the 0.2 % discard RMSE\n",
    "    # discard_rmse = overall_results[dataset][system][\"Discard Fraction 0.2\"][\"rmse\"]\n",
    "    # ax.axhline(discard_rmse, color='red', linestyle='--', label=\"Discard Fraction 0.2 RMSE\")\n",
    "\n",
    "    ax.set_xticklabels(methods, rotation=90)\n",
    "    ax.set_title(system)\n",
    "\n",
    "    # Remove x grid ylines\n",
    "    ax.xaxis.grid(False)\n",
    "\n",
    "# Plot the RMSEs\n",
    "fig, axs = get_subplots(systems)\n",
    "\n",
    "for i, system in enumerate(systems):\n",
    "    ax = axs[i]\n",
    "    plot_rmses_on_ax(ax, \"standard\", system, 100)\n",
    "    ax.set_ylabel(\"$\\\\mathrm{RMSE}(\\\\langle \\\\Delta G \\\\rangle)$ \\n/ kcal mol$^{-1}$\")\n",
    "    ax.set_title(system)\n",
    "\n",
    "    # Remove x labels from first 3 plots\n",
    "    if i < 3:\n",
    "        ax.set_xticklabels([])\n",
    "\n",
    "    # Remove y labels from right column\n",
    "    if i % 2 == 1:\n",
    "        ax.set_ylabel(\"\")\n",
    "\n",
    "    # Add the legend to the last plot\n",
    "    if i == len(systems) - 1:\n",
    "        ax.legend(bbox_to_anchor=(1.05, -0.3), loc='upper left')\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "fig.savefig(\"output_single/rmses_standard.png\", dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distributions of Unsigned Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_unsigned_error_distribution_on_ax(ax: Axes, dataset: str, system: str) -> None:\n",
    "    # Get the squared errors\n",
    "    df_ses = pd.DataFrame({method: distributions[dataset][system][method][\"mues\"] for method in automated_methods})\n",
    "    sns.violinplot(data=df_ses, ax=ax, palette=colors)\n",
    "    ax.set_title(system)\n",
    "    ax.set_ylabel(\"Unsigned Error / kcal mol$^{-1}$\")\n",
    "    ax.set_xticklabels(methods, rotation=90)\n",
    "    \n",
    "    # Get the minimum possible fixed-time RMSE and plot a horizontal to show it\n",
    "    min_rmse = np.min(fixed_trunc_error_series[dataset][system][\"rmse_series\"])\n",
    "    ax.axhline(min_rmse, color='black', linestyle='--', label=\"Minimum Fixed-Time RMSE\")\n",
    "\n",
    "# Plot the squared errors\n",
    "fig, axs = get_subplots(systems)\n",
    "\n",
    "for i, system in enumerate(systems):\n",
    "    ax = axs[i]\n",
    "    plot_unsigned_error_distribution_on_ax(ax, \"standard\", system)\n",
    "    ax.set_title(system)\n",
    "\n",
    "    # Remove x labels from first 3 plots\n",
    "    if i < 3:\n",
    "        ax.set_xticklabels([])\n",
    "\n",
    "    # Remove y labels from right column\n",
    "    if i % 2 == 1:\n",
    "        ax.set_ylabel(\"\")\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "fig.savefig(\"output_single/unsigned_errors_standard.png\", dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contour Plots of Components of Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on the code above\n",
    "def plot_contour_plot_on_axis(ax: Axes, dataset: str, system: str) -> None:\n",
    "    # Get the fixed-time bias and sem\n",
    "    bias = fixed_trunc_error_series[dataset][system][\"bias_series\"]\n",
    "    sem = fixed_trunc_error_series[dataset][system][\"sem_series\"]\n",
    "    ax.plot(bias, sem, label=\"Fixed Truncation\\n Time Limit\", zorder=2)\n",
    "\n",
    "    # Now, get the biases, variances, and associated CIs for all of the methods.\n",
    "    # We need these to decide how big the grid needs to be\n",
    "    biases = [overall_results[dataset][system][method][\"bias\"] for method in automated_methods]\n",
    "    sems = [overall_results[dataset][system][method][\"variance\"]**0.5 for method in automated_methods]\n",
    "    bias_cis_upper = [overall_results[dataset][system][method][\"mean_ci\"][1] - overall_results[dataset][system][method][\"bias\"] for method in automated_methods]\n",
    "    bias_cis_lower = [overall_results[dataset][system][method][\"bias\"] - overall_results[dataset][system][method][\"mean_ci\"][0] for method in automated_methods]\n",
    "    sem_cis_upper = [overall_results[dataset][system][method][\"var_ci\"][1]**0.5 - overall_results[dataset][system][method][\"variance\"]**0.5 for method in automated_methods]\n",
    "    sem_cis_lower = [overall_results[dataset][system][method][\"variance\"]**0.5 - overall_results[dataset][system][method][\"var_ci\"][0]**0.5 for method in automated_methods]\n",
    "\n",
    "    # Create a grid of points\n",
    "    max_bias_or_sem = max(max(biases), max(sems))\n",
    "    limit = max_bias_or_sem + max_bias_or_sem * 0.1\n",
    "    x = np.linspace(-limit, limit, 1000)\n",
    "    y = np.linspace(-limit, limit, 1000)\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "\n",
    "    # Calculate distance from origin\n",
    "    Z = np.sqrt(X**2 + Y**2)\n",
    "\n",
    "    # Create a contour plot so that there are 10 contours\n",
    "    d_error = limit / 8\n",
    "    # Round error steps up to nearest 0.05 kcal/mol\n",
    "    # d_error = np.ceil(d_error / 0.05) * 0.05\n",
    "    d_error = round(d_error, 2)\n",
    "    contour_levels = np.arange(0, np.max(Z), d_error)\n",
    "    contourf = ax.contourf(X, Y, Z, levels=contour_levels, cmap='viridis')\n",
    "\n",
    "    # Add on the equilibration detection results\n",
    "    for i, method in enumerate(automated_methods):\n",
    "        ax.errorbar(biases[i], sems[i], xerr=[[bias_cis_lower[i]], [bias_cis_upper[i]]], yerr=[[sem_cis_lower[i]], [sem_cis_upper[i]]], \n",
    "                                              fmt='none', ecolor='black', capsize=5, markerfacecolor='white', zorder=1)\n",
    "\n",
    "        ax.scatter(biases[i], sems[i], label=method, edgecolors='black', linewidth=1, s=50, zorder=2, color=colors[i])\n",
    "\n",
    "    # Set x and y limits\n",
    "    negative_limit = -limit * 0.02\n",
    "    ax.set_xlim([negative_limit, limit])\n",
    "    ax.set_ylim([negative_limit, limit])\n",
    "\n",
    "    # Add a horizontal colour bar below the plot\n",
    "    cbar = plt.colorbar(contourf, orientation='horizontal', location='top')\n",
    "    cbar.set_label(\"$\\\\mathrm{RMSE}(\\\\langle \\\\Delta G \\\\rangle )$ / kcal mol$^{-1}$\")\n",
    "\n",
    "    # Set x and y labels, and force aspect ratio to be equal\n",
    "    ax.set_xlabel(\"$\\\\langle \\\\mathrm{Bias}(\\\\langle \\\\Delta G \\\\rangle) \\\\rangle$ / kcal mol$^{-1}$\")\n",
    "    ax.set_ylabel(\"$\\\\mathrm{SD}(\\\\langle \\\\Delta G \\\\rangle)$ / kcal mol$^{-1}$\")\n",
    "    ax.set_aspect('equal', adjustable='box')\n",
    "\n",
    "# Plot the contour plots\n",
    "fig, axs = get_subplots(systems, scale_y=1.2)\n",
    "\n",
    "for i, system in enumerate(systems):\n",
    "    ax = axs[i]\n",
    "    plot_contour_plot_on_axis(ax, \"standard\", system)\n",
    "    ax.set_title(system, pad=60)\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "# Set the legend on the last plot\n",
    "axs[-2].legend(loc='center left', bbox_to_anchor=(1.1, 0.5))\n",
    "\n",
    "fig.savefig(\"output_single/bias_vs_sem_contour_plots.png\", dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overall Plots\n",
    "\n",
    "Combine the plots of error components, discard times, and RMSEs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a grid of 5 sections, one for each system. For each section, create a grid of 4 plots.\n",
    "\n",
    "fig = plt.figure(figsize=(30, 6))\n",
    "\n",
    "# Gridspec with 2 rows and 10 columns\n",
    "# gs_outer = gridspec.GridSpec(1, 5, figure=fig)\n",
    "subfigs = fig.subfigures(1, 5)\n",
    "\n",
    "axs = []\n",
    "for i, system in enumerate(systems):\n",
    "\n",
    "    # Get subfigure, grid spec, and add title\n",
    "    subfig = subfigs[i]\n",
    "    gs = gridspec.GridSpec(2, 2, figure=subfig, hspace=0.05, wspace=0.05)\n",
    "    subfig.suptitle(system, fontsize=16, fontweight='bold')\n",
    "\n",
    "    # Create subplots with axes shared as required\n",
    "    components_ax = subfig.add_subplot(gs[1,0])\n",
    "    discard_ax = subfig.add_subplot(gs[0,0], sharex=components_ax)\n",
    "    rmse_ax = subfig.add_subplot(gs[1,1], sharey=components_ax)\n",
    "    unused_ax = subfig.add_subplot(gs[0,1])\n",
    "    \n",
    "    # Plot/ delete axes\n",
    "    plot_error_components_on_ax(components_ax, \"standard\", system, 100)\n",
    "    plot_discard_times_on_ax(discard_ax, \"standard\", system, 100)\n",
    "    plot_rmses_on_ax(rmse_ax, \"standard\", system, 100)\n",
    "    subfig.delaxes(unused_ax)\n",
    "\n",
    "    # Remove unnecessary labels/ titles\n",
    "    components_ax.set_title(\"\")\n",
    "    if i == 0:\n",
    "        components_ax.legend(bbox_to_anchor=(-0.05, -0.3), loc='upper left')\n",
    "    rmse_ax.set_title(\"$\\\\mathrm{RMSE}(\\\\langle \\\\Delta G \\\\rangle)$\")\n",
    "    rmse_ax.set_ylabel(\"\")\n",
    "    discard_ax.set_title(\"Truncation Time\")\n",
    "    discard_ax.set_xlabel(\"\")\n",
    "    # Hide the numbers on the x axis for the discard times plot, but don't set labels to empty as this effects the RMSE plot\n",
    "    discard_ax.tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False)\n",
    "    rmse_ax.tick_params(axis='y', which='both', left=False, right=False, labelleft=False)\n",
    "    \n",
    "    # If this isn't the first system, remove the labels from the discard times plot\n",
    "    if i != 0:\n",
    "        discard_ax.set_yticklabels([])\n",
    "        \n",
    "\n",
    "fig.savefig(\"output_single/combined_plots.png\", dpi=300, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a grid of 5 sections, one for each system. For each section, create a grid of 4 plots.\n",
    "\n",
    "fig = plt.figure(figsize=(13.5, 9))\n",
    "\n",
    "# Gridspec with 2 rows and 10 columns\n",
    "# gs_outer = gridspec.GridSpec(1, 5, figure=fig)\n",
    "# subfigs = fig.subfigures(2, 3)\n",
    "subfigs = fig.subfigures(2, 3, wspace=0.1, hspace=0.1)\n",
    "subfigs = subfigs.flatten()\n",
    "\n",
    "axs = []\n",
    "for i, system in enumerate(systems):\n",
    "\n",
    "    # Get subfigure, grid spec, and add title\n",
    "    subfig = subfigs[i]\n",
    "    gs = gridspec.GridSpec(2, 2, figure=subfig, hspace=0.05, wspace=0.05)\n",
    "    subfig.suptitle(system, fontsize=16, fontweight='bold', y=1.02)\n",
    "\n",
    "    # Create subplots with axes shared as required\n",
    "    components_ax = subfig.add_subplot(gs[1,0])\n",
    "    discard_ax = subfig.add_subplot(gs[0,0], sharex=components_ax)\n",
    "    rmse_ax = subfig.add_subplot(gs[1,1], sharey=components_ax)\n",
    "    unused_ax = subfig.add_subplot(gs[0,1])\n",
    "    \n",
    "    # Plot/ delete axes\n",
    "    plot_error_components_on_ax(components_ax, \"standard\", system, 100)\n",
    "    plot_discard_times_on_ax(discard_ax, \"standard\", system, 100)\n",
    "    plot_rmses_on_ax(rmse_ax, \"standard\", system, 100)\n",
    "    subfig.delaxes(unused_ax)\n",
    "\n",
    "    # Remove unnecessary labels/ titles\n",
    "    components_ax.set_title(\"\")\n",
    "    if i == 2:\n",
    "        # components_ax.legend(bbox_to_anchor=(-0.5, -0.45), loc='upper left')\n",
    "        components_ax.legend(bbox_to_anchor=(0.05, -2.0), loc='upper left')\n",
    "\n",
    "    # Remove x labels from first two plots\n",
    "    if i < 2:\n",
    "        rmse_ax.set_xticklabels([])\n",
    "\n",
    "    rmse_ax.set_title(\"$\\\\mathrm{RMSE}(\\\\langle \\\\Delta G \\\\rangle)$\")\n",
    "    rmse_ax.set_ylabel(\"\")\n",
    "    discard_ax.set_title(\"Truncation Time\")\n",
    "    discard_ax.set_xlabel(\"\")\n",
    "    # Hide the numbers on the x axis for the discard times plot, but don't set labels to empty as this effects the RMSE plot\n",
    "    discard_ax.tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False)\n",
    "    rmse_ax.tick_params(axis='y', which='both', left=False, right=False, labelleft=False)\n",
    "    \n",
    "    # If this isn't the first system in a row, remove the labels from the discard times plot\n",
    "    if i not in [0, 3]:\n",
    "        discard_ax.set_yticklabels([])\n",
    "        \n",
    "\n",
    "fig.savefig(\"output_single/combined_plots_reformatted.png\", dpi=300, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat above plot, but show distributions of unsigned\n",
    "# errors instead of RMSE of dataset\n",
    "\n",
    "fig = plt.figure(figsize=(30, 6))\n",
    "\n",
    "# Gridspec with 2 rows and 10 columns\n",
    "# gs_outer = gridspec.GridSpec(1, 5, figure=fig)\n",
    "subfigs = fig.subfigures(1, 5)\n",
    "\n",
    "axs = []\n",
    "for i, system in enumerate(systems):\n",
    "\n",
    "    # Get subfigure, grid spec, and add title\n",
    "    subfig = subfigs[i]\n",
    "    gs = gridspec.GridSpec(2, 2, figure=subfig, hspace=0.05, wspace=0.05)\n",
    "    subfig.suptitle(system, fontsize=16, fontweight='bold')\n",
    "\n",
    "    # Create subplots with axes shared as required\n",
    "    components_ax = subfig.add_subplot(gs[1,0])\n",
    "    discard_ax = subfig.add_subplot(gs[0,0], sharex=components_ax)\n",
    "    rmse_ax = subfig.add_subplot(gs[1,1], sharey=components_ax)\n",
    "    unused_ax = subfig.add_subplot(gs[0,1])\n",
    "    \n",
    "    # Plot/ delete axes\n",
    "    plot_error_components_on_ax(components_ax, \"standard\", system, 100)\n",
    "    plot_discard_times_on_ax(discard_ax, \"standard\", system, 100)\n",
    "    plot_unsigned_error_distribution_on_ax(rmse_ax, \"standard\", system)\n",
    "    subfig.delaxes(unused_ax)\n",
    "\n",
    "    # Remove unnecessary labels/ titles\n",
    "    components_ax.set_title(\"\")\n",
    "    if i == 0:\n",
    "        components_ax.legend(bbox_to_anchor=(-0.05, -0.3), loc='upper left')\n",
    "    rmse_ax.set_title(\"Unsigned Errors\")\n",
    "    rmse_ax.set_ylabel(\"\")\n",
    "    discard_ax.set_title(\"Truncation Time\")\n",
    "    discard_ax.set_xlabel(\"\")\n",
    "    # Hide the numbers on the x axis for the discard times plot, but don't set labels to empty as this effects the RMSE plot\n",
    "    discard_ax.tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False)\n",
    "    rmse_ax.tick_params(axis='y', which='both', left=False, right=False, labelleft=False)\n",
    "    \n",
    "    # If this isn't the first system, remove the labels from the discard times plot\n",
    "    if i != 0:\n",
    "        discard_ax.set_yticklabels([])\n",
    "        \n",
    "\n",
    "fig.savefig(\"output_single/combined_plots_unsigned_errors.png\", dpi=300, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a grid of 5 sections, one for each system. For each section, create a grid of 4 plots.\n",
    "\n",
    "fig = plt.figure(figsize=(13.5, 9))\n",
    "\n",
    "# Gridspec with 2 rows and 10 columns\n",
    "# gs_outer = gridspec.GridSpec(1, 5, figure=fig)\n",
    "# subfigs = fig.subfigures(2, 3)\n",
    "subfigs = fig.subfigures(2, 3, wspace=0.1, hspace=0.1)\n",
    "subfigs = subfigs.flatten()\n",
    "\n",
    "axs = []\n",
    "for i, system in enumerate(systems):\n",
    "\n",
    "    # Get subfigure, grid spec, and add title\n",
    "    subfig = subfigs[i]\n",
    "    gs = gridspec.GridSpec(2, 2, figure=subfig, hspace=0.05, wspace=0.05)\n",
    "    subfig.suptitle(system, fontsize=16, fontweight='bold', y=1.02)\n",
    "\n",
    "    # Create subplots with axes shared as required\n",
    "    components_ax = subfig.add_subplot(gs[1,0])\n",
    "    discard_ax = subfig.add_subplot(gs[0,0], sharex=components_ax)\n",
    "    rmse_ax = subfig.add_subplot(gs[1,1], sharey=components_ax)\n",
    "    unused_ax = subfig.add_subplot(gs[0,1])\n",
    "    \n",
    "    # Plot/ delete axes\n",
    "    plot_error_components_on_ax(components_ax, \"standard\", system, 100)\n",
    "    plot_discard_times_on_ax(discard_ax, \"standard\", system, 100)\n",
    "    plot_unsigned_error_distribution_on_ax(rmse_ax, \"standard\", system)\n",
    "    subfig.delaxes(unused_ax)\n",
    "\n",
    "    # Remove unnecessary labels/ titles\n",
    "    components_ax.set_title(\"\")\n",
    "    if i == 2:\n",
    "        # components_ax.legend(bbox_to_anchor=(-0.5, -0.45), loc='upper left')\n",
    "        components_ax.legend(bbox_to_anchor=(0.05, -2.0), loc='upper left')\n",
    "\n",
    "    # Remove x labels from first two plots\n",
    "    if i < 2:\n",
    "        rmse_ax.set_xticklabels([])\n",
    "\n",
    "    rmse_ax.set_title(\"$\\\\mathrm{RMSE}(\\\\langle \\\\Delta G \\\\rangle)$\")\n",
    "    rmse_ax.set_ylabel(\"\")\n",
    "    discard_ax.set_title(\"Truncation Time\")\n",
    "    discard_ax.set_xlabel(\"\")\n",
    "    # Hide the numbers on the x axis for the discard times plot, but don't set labels to empty as this effects the RMSE plot\n",
    "    discard_ax.tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False)\n",
    "    rmse_ax.tick_params(axis='y', which='both', left=False, right=False, labelleft=False)\n",
    "    \n",
    "    # If this isn't the first system in a row, remove the labels from the discard times plot\n",
    "    if i not in [0, 3]:\n",
    "        discard_ax.set_yticklabels([])\n",
    "        \n",
    "\n",
    "fig.savefig(\"output_single/combined_plots_unsigned_errors_reformatted.png\", dpi=300, bbox_inches='tight')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "red_reproduce",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
