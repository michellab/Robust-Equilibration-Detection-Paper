{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detailed Analysis of Results for MIF\n",
    "\n",
    "This notebook is organised as follows:\n",
    "\n",
    "- [Load and process data](#load)\n",
    "- [Plot bias, sem and rmse](#plot)\n",
    "- [Plot specific examples](#examples)\n",
    "- [Compare results to max achievable performance](#max)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import red\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from matplotlib.axes import Axes\n",
    "from matplotlib.figure import Figure\n",
    "from matplotlib import gridspec\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "colors = sns.color_palette('colorblind')\n",
    "\n",
    "def get_subplots(systems: list[str], scale_x: float = 1, scale_y: float =1) -> tuple[plt.Figure, list[plt.Axes]]:\n",
    "    # Plot two columns side-by-side\n",
    "    n_cols = min(2, len(systems))\n",
    "    n_rows = int(np.ceil(len(systems) / n_cols))\n",
    "    # fig, axs = plt.subplots(n_rows, n_cols, figsize=(3 * n_cols, 5*n_rows))\n",
    "    fig, axs = plt.subplots(n_rows, n_cols, figsize=(scale_x*3 * n_cols, scale_y*3*n_rows))\n",
    "    if len(systems) == 1:\n",
    "        axs = [axs]\n",
    "    else:\n",
    "        axs = axs.flatten()\n",
    "\n",
    "    # Set titles\n",
    "    for i, system in enumerate(systems):\n",
    "        axs[i].set_title(system)\n",
    "\n",
    "    # Remove any unused axes\n",
    "    for i in range(len(systems), len(axs)):\n",
    "        fig.delaxes(axs[i])\n",
    "\n",
    "    return fig, axs\n",
    "\n",
    "def sanitise_name(name: str) -> str:\n",
    "    # Replace underscores with spaces\n",
    "    name = name.replace('_', ' ')\n",
    "    \n",
    "    # Split the string by spaces and newlines\n",
    "    words = name.split()\n",
    "    \n",
    "    # Capitalize the first letter of each word\n",
    "    capitalized_words = [word[0].upper() + word[1:] if word else '' for word in words]\n",
    "    \n",
    "    # Join the words back together with spaces\n",
    "    sanitized_name = ' '.join(capitalized_words)\n",
    "    \n",
    "    # Restore newlines\n",
    "    sanitized_name = sanitized_name.replace(' \\n ', '\\n')\n",
    "    \n",
    "    return sanitized_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../compute_equil_times/output/synthetic_data_bound_vanish_with_equil_times_saved.pkl\", \"rb\") as f:\n",
    "    data = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace any keys in data called \"Window Size $\\\\sqrt(n)$\" with Window Size $\\\\sqrt{n}$. Do this recursively.\n",
    "replaced_data = {}\n",
    "\n",
    "for dataset in data:\n",
    "    replaced_data[dataset] = {}\n",
    "    for system in [sys for sys in data[dataset] if sys != \"times\"]:\n",
    "        replaced_data[dataset][system] = {}\n",
    "        for repeat in data[dataset][system]:\n",
    "            replaced_data[dataset][system][repeat] = {}\n",
    "            for key in data[dataset][system][repeat]:\n",
    "                new_key = key.replace(\"Window Size $\\\\sqrt(n)$\", \"Window Size $\\\\sqrt{N_{n_0}}$\")\n",
    "                replaced_data[dataset][system][repeat][new_key] = data[dataset][system][repeat][key]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../compute_equil_times/output/synthetic_data_bound_vanish_with_equil_times.pkl\", \"wb\") as f:\n",
    "    pkl.dump(replaced_data, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and process data <a id=\"load\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../compute_equil_times/output/synthetic_data_bound_vanish_with_equil_times.pkl\", \"rb\") as f:\n",
    "    data = pkl.load(f)\n",
    "\n",
    "datasets = list(data.keys())\n",
    "# Sort datasets to put standard first\n",
    "datasets = sorted(datasets, key=lambda x: x != \"standard\")\n",
    "systems = [system for system in data[datasets[0]].keys() if system != \"times\"]\n",
    "methods = [method for method in data[datasets[0]][systems[0]][0].keys() if method != \"data\"]\n",
    "\n",
    "# Create version of the data with MIF only\n",
    "mif_data = {dataset: data[dataset][\"MIF\"] for dataset in datasets}\n",
    "\n",
    "# Seperate out automated and fixed methods\n",
    "automated_methods = [method for method in methods if \"Discard\" not in method]\n",
    "fixed_methods = [method for method in methods if \"Discard\" in method]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap(data: np.ndarray, fn: callable = lambda x: x, n_bootstraps: int = 10_000) -> tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"Get the 95 % confidence interval for the mean\"\"\"\n",
    "    means = np.zeros(n_bootstraps)\n",
    "    for i in range(n_bootstraps):\n",
    "        # Get a random list of indices\n",
    "        values = np.random.choice(data, size=len(data), replace=True)\n",
    "        # Apply passed function to the data\n",
    "        values = fn(values)\n",
    "        # Take mean. If fn has already been applied to give a single value,\n",
    "        # e.g. the variance, then this will not change the value.\n",
    "        means[i] = np.mean(values)\n",
    "    return np.percentile(means, [2.5, 97.5]), means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"standard\"][\"T4L\"][0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute statistics for all datasets.\n",
    "overall_results = {}\n",
    "distributions = {}\n",
    "\n",
    "# Can't pickle lambda functions for multiprocessing, so define the functions here\n",
    "\n",
    "for dataset in tqdm(datasets):\n",
    "    overall_results[dataset] = {}\n",
    "    distributions[dataset] = {}\n",
    "    for system in systems:\n",
    "        overall_results[dataset][system] = {}\n",
    "        distributions[dataset][system] = {}\n",
    "\n",
    "        for method in methods:\n",
    "            overall_results[dataset][system][method] = {}\n",
    "            distributions[dataset][system][method] = {}\n",
    "            local_data = {i: data[dataset][system][i][method] for i in data[dataset][system]}\n",
    "\n",
    "            # Basic stats\n",
    "            means = np.array([local_data[i][\"mean\"] for i in local_data])\n",
    "            bias = means.mean()\n",
    "            variance = means.var()\n",
    "\n",
    "            # MUEs and RMSEs are easy to calculate as the true answer is 0\n",
    "            mues = abs(means)\n",
    "            mue = mues.mean()\n",
    "            mses = means ** 2\n",
    "            rmse = np.sqrt(mses.mean())\n",
    "\n",
    "            # Check time taken for the calculations\n",
    "            times = np.array([local_data[i][\"time\"] for i in local_data])\n",
    "            time = times.mean()\n",
    "\n",
    "            # Fraction of data discarded\n",
    "            fracs = np.array([local_data[i][\"frac_discarded\"] for i in local_data])\n",
    "            frac_discarded = fracs.mean()\n",
    "\n",
    "            # Get the 95 % confidence intervals\n",
    "            mean_ci, mean_distr = bootstrap(means)\n",
    "            frac_ci, frac_distr = bootstrap(fracs)\n",
    "            time_ci, time_distr = bootstrap(times)\n",
    "            var_ci, var_distr = bootstrap(means, np.var)\n",
    "            mue_ci, mue_distr = bootstrap(means, abs)\n",
    "            # CIs for the RMSE - need to square root to get the RMSE\n",
    "            rmse_ci, rmse_distr = bootstrap(means, np.square)\n",
    "            rmse_ci = np.sqrt(rmse_ci)\n",
    "            rmse_distr = np.sqrt(rmse_distr)\n",
    "\n",
    "            # Save the results\n",
    "            overall_results[dataset][system][method][\"bias\"] = bias\n",
    "            overall_results[dataset][system][method][\"variance\"] = variance\n",
    "            overall_results[dataset][system][method][\"mue\"] = mue\n",
    "            overall_results[dataset][system][method][\"rmse\"] = rmse\n",
    "            overall_results[dataset][system][method][\"time\"] = time\n",
    "            overall_results[dataset][system][method][\"frac_discarded\"] = frac_discarded\n",
    "            overall_results[dataset][system][method][\"mean_ci\"] = mean_ci\n",
    "            overall_results[dataset][system][method][\"frac_ci\"] = frac_ci\n",
    "            overall_results[dataset][system][method][\"time_ci\"] = time_ci\n",
    "            overall_results[dataset][system][method][\"var_ci\"] = var_ci\n",
    "            overall_results[dataset][system][method][\"mue_ci\"] = mue_ci\n",
    "            overall_results[dataset][system][method][\"rmse_ci\"] = rmse_ci\n",
    "\n",
    "            # Save the distributions\n",
    "            distributions[dataset][system][method][\"means\"] = means\n",
    "            distributions[dataset][system][method][\"fracs\"] = fracs\n",
    "            distributions[dataset][system][method][\"times\"] = times\n",
    "            distributions[dataset][system][method][\"mues\"] = mues\n",
    "            distributions[dataset][system][method][\"mses\"] = mses\n",
    "\n",
    "            # Save the bootstrap distributions\n",
    "            distributions[dataset][system][method][\"mean_boot\"] = mean_distr\n",
    "            distributions[dataset][system][method][\"frac_boot\"] = frac_distr\n",
    "            distributions[dataset][system][method][\"time_boot\"] = time_distr\n",
    "            distributions[dataset][system][method][\"var_boot\"] = var_distr\n",
    "            distributions[dataset][system][method][\"mue_boot\"] = mue_distr\n",
    "            distributions[dataset][system][method][\"rmse_boot\"] = rmse_distr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"output/overall_results.pkl\", \"rb\") as f:\n",
    "    overall_results = pkl.load(f)\n",
    "\n",
    "with open(\"output/distributions.pkl\", \"rb\") as f:\n",
    "    distributions = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the results\n",
    "with open(\"output/overall_results.pkl\", \"wb\") as f:\n",
    "    pkl.dump(overall_results, f)\n",
    "\n",
    "with open(\"output/distributions.pkl\", \"wb\") as f:\n",
    "    pkl.dump(distributions, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect the RMSEs into dataframes. We'll create one table for each dataset.\n",
    "\n",
    "for dataset in datasets:\n",
    "    # Save a latex table of results\n",
    "    rows = []\n",
    "    for method in automated_methods:\n",
    "        system_rmses = {}\n",
    "        for system in systems:\n",
    "            rmse = overall_results[dataset][system][method][\"rmse\"]\n",
    "            upper_ci = overall_results[dataset][system][method][\"rmse_ci\"][1]\n",
    "            lower_ci = overall_results[dataset][system][method][\"rmse_ci\"][0]\n",
    "            system_rmses[system] = f\"${rmse:.3f}_{{{lower_ci:.3f}}}^{{{upper_ci:.3f}}}$\"\n",
    "        row = {\"Method\": method, **system_rmses}\n",
    "        rows.append(row)\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    df.to_latex(f\"output/rmse_table_{dataset}.tex\", index=False, escape=False, column_format= \"l\" + \"c\" * len(systems))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation of A Few Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"standard\"][\"MIF\"][0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a few examples\n",
    "\n",
    "idx, g, ess = red.detect_equilibration_window(data[\"standard\"][\"MIF\"][9][\"data\"], method=\"min_sse\", plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx, g, ess = red.detect_equilibration_init_seq(data[\"standard\"][\"MIF\"][9][\"data\"], sequence_estimator=\"positive\", plot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx, g, ess = red.detect_equilibration_init_seq(data[\"standard\"][\"MIF\"][9][\"data\"], sequence_estimator=\"initial_convex\", plot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a set of 3 x 2 subplots\n",
    "from matplotlib import gridspec\n",
    "\n",
    "example_data_full = data[\"standard\"][\"MIF\"][9][\"data\"]\n",
    "example_data = example_data_full[:]\n",
    "example_times = np.linspace(0, 8, len(example_data_full)+1)[1:][:]\n",
    "fig = plt.figure(figsize=(13, 5))\n",
    "gridspec_obj = gridspec.GridSpec(1, 4, figure=fig)\n",
    "\n",
    "# gridspec_obj[0].set_title(\"Min SSE\")\n",
    "\n",
    "red.detect_equilibration_window(example_data, example_times, window_size_fn=None, window_size=1, plot=True, figure=fig, grid_spec_obj=gridspec_obj[0])\n",
    "red.detect_equilibration_window(example_data, example_times, plot=True, figure=fig, grid_spec_obj=gridspec_obj[1])\n",
    "red.detect_equilibration_init_seq(example_data, example_times, sequence_estimator=\"positive\", plot = True, figure=fig, grid_spec_obj=gridspec_obj[2])\n",
    "red.detect_equilibration_init_seq(example_data, example_times, sequence_estimator=\"initial_convex\", plot = True, figure=fig, grid_spec_obj=gridspec_obj[3])\n",
    "\n",
    "# Get all axes in the figure\n",
    "axs = fig.get_axes()\n",
    "# Remove all legends\n",
    "for i, ax in enumerate(axs):\n",
    "    ax.legend().remove()\n",
    "\n",
    "    # Keep only the leftmost y labels\n",
    "    if i > 1:\n",
    "        ax.set_ylabel(\"\")\n",
    "    \n",
    "    # Set 1/ estimated variance as the y label for bottom left axes\n",
    "    if i == 1:\n",
    "        ax.set_ylabel(\"$(\\\\widehat{\\\\mathrm{Var}}_{\\\\mathrm{Trajs}}(\\\\langle A \\\\rangle_{[n_{0},N]}))^{-1}$ \\n/ kcal$^{-2}$ mol$^2$\")\n",
    "\n",
    "    # Set title\n",
    "    if i == 0:\n",
    "        ax.set_title(\"Uncorrelated Estimate\")\n",
    "    if i == 3:\n",
    "        ax.set_title(\"Window Size $\\\\sqrt{N_{n_0}}$\")\n",
    "    elif i == 6:\n",
    "        ax.set_title(\"Initial Sequence: Chodera\")\n",
    "    elif i == 9:\n",
    "        ax.set_title(\"Initial Sequence: Convex\")\n",
    "\n",
    "    # Remove grids from bottom right y axes\n",
    "    if i in [2, 5, 8, 11]:\n",
    "        ax.yaxis.grid(False)\n",
    "        # Use the same colour as the line plotted\n",
    "        lag_color = ax.get_lines()[0].get_color()\n",
    "        ax.tick_params(axis='y', labelcolor=lag_color)\n",
    "\n",
    "    # Set the y axis label for the lag index\n",
    "    if i == 11:\n",
    "        ax.set_ylabel(\"Window Size or \\n Max Lag Index\", color=lag_color)\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "# Combine the axis labels from the tow last axes into a single legend\n",
    "handles_see, labels_see = axs[-2].get_legend_handles_labels()\n",
    "handles_lag, labels_lag = axs[-1].get_legend_handles_labels()\n",
    "fig.legend(handles_see + handles_lag, [\"$(\\\\widehat{\\\\mathrm{Var}}_{\\\\mathrm{Trajs}}(\\\\langle A \\\\rangle_{[n_{0},N]}))^{-1}$\", \"Equilibration Time\"] + [\"Window Size or Max Lag Index\"], loc='upper right', bbox_to_anchor=(0.62, -0.03))\n",
    "\n",
    "\n",
    "fig.savefig(\"output/single_example_detection_uncorr.png\", dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a set of 3 x 2 subplots\n",
    "from matplotlib import gridspec\n",
    "\n",
    "example_data_full = data[\"standard\"][\"MIF\"][2][\"data\"]\n",
    "example_data = example_data_full[:]\n",
    "example_times = np.linspace(0, 8, len(example_data_full)+1)[1:][:]\n",
    "fig = plt.figure(figsize=(13, 5))\n",
    "gridspec_obj = gridspec.GridSpec(1, 4, figure=fig)\n",
    "\n",
    "# gridspec_obj[0].set_title(\"Min SSE\")\n",
    "\n",
    "red.detect_equilibration_init_seq(example_data, example_times, sequence_estimator=\"positive\", plot = True, figure=fig, grid_spec_obj=gridspec_obj[0])\n",
    "red.detect_equilibration_init_seq(example_data, example_times, sequence_estimator=\"initial_positive\", plot = True, figure=fig, grid_spec_obj=gridspec_obj[1])\n",
    "red.detect_equilibration_init_seq(example_data, example_times, sequence_estimator=\"initial_monotone\", plot = True, figure=fig, grid_spec_obj=gridspec_obj[2])\n",
    "red.detect_equilibration_init_seq(example_data, example_times, sequence_estimator=\"initial_convex\", plot = True, figure=fig, grid_spec_obj=gridspec_obj[3])\n",
    "\n",
    "# Get all axes in the figure\n",
    "axs = fig.get_axes()\n",
    "# Remove all legends\n",
    "for i, ax in enumerate(axs):\n",
    "    ax.legend().remove()\n",
    "\n",
    "    # Keep only the leftmost y labels\n",
    "    if i > 1:\n",
    "        ax.set_ylabel(\"\")\n",
    "    \n",
    "    # Set 1/ estimated variance as the y label for bottom left axes\n",
    "    if i == 1:\n",
    "        ax.set_ylabel(\"$(\\\\widehat{\\\\mathrm{Var}}_{\\\\mathrm{Trajs}}(\\\\langle A \\\\rangle_{[n_{0},N]}))^{-1}$ \\n/ kcal$^{-2}$ mol$^2$\")\n",
    "\n",
    "    # Set title\n",
    "    if i == 0:\n",
    "        ax.set_title(\"Chodera\")\n",
    "    if i == 3:\n",
    "        ax.set_title(\"Initial Positive\")\n",
    "    elif i == 6:\n",
    "        ax.set_title(\"Initial Monotone\")\n",
    "    elif i == 9:\n",
    "        ax.set_title(\"Initial Convex\")\n",
    "\n",
    "    # Remove grids from bottom right y axes\n",
    "    if i in [2, 5, 8, 11]:\n",
    "        ax.yaxis.grid(False)\n",
    "        # Use the same colour as the line plotted\n",
    "        lag_color = ax.get_lines()[0].get_color()\n",
    "        ax.tick_params(axis='y', labelcolor=lag_color)\n",
    "\n",
    "    # Set the y axis label for the lag index\n",
    "    if i == 11:\n",
    "        ax.set_ylabel(\"Window Size or \\n Max Lag Index\", color=lag_color)\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "# Combine the axis labels from the tow last axes into a single legend\n",
    "handles_see, labels_see = axs[-2].get_legend_handles_labels()\n",
    "handles_lag, labels_lag = axs[-1].get_legend_handles_labels()\n",
    "fig.legend(handles_see + handles_lag, [\"$(\\\\widehat{\\\\mathrm{Var}}_{\\\\mathrm{Trajs}}(\\\\langle A \\\\rangle_{[n_{0},N]}))^{-1}$\", \"Equilibration Time\"] + [\"Window Size or Max Lag Index\"], loc='upper right', bbox_to_anchor=(0.62, -0.03))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_lag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data Creation Parameters and Plot Bias, SEM and RMSE <a id=\"plot\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../synthetic_data_creation/output/synthetic_data_params.pkl\", \"rb\") as f:\n",
    "    params = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exp_decay(x: np.ndarray, a: float, b: float) -> np.ndarray:\n",
    "    return a * np.exp(-b * x)\n",
    "\n",
    "def compute_bias(times: np.ndarray,\n",
    "                 exp_params: tuple[float, float],\n",
    "                 fast_exp_params: tuple[float, float]) -> np.ndarray:\n",
    "    \"\"\"Compute the bias for the given times\"\"\"\n",
    "    # First, compute the bias at each point in the series\n",
    "    bias = exp_decay(times, *exp_params) + exp_decay(times, *fast_exp_params)\n",
    "    # Then, for each data point, average over all subsequent data points to get the mean biases\n",
    "    mean_bias = np.zeros(len(bias))\n",
    "    for i, _ in enumerate(bias):\n",
    "        n_points = len(bias) - i\n",
    "        mean_bias[i] = np.sum(bias[i:]) / n_points    \n",
    "\n",
    "    return mean_bias\n",
    "\n",
    "def compute_mean_variance(times: np.ndarray,\n",
    "                          autocov_series: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Compute the mean variance over the times passed.\"\"\"\n",
    "    # Precompute cumulative sums\n",
    "    # return autocov_series[0] + 2*np.sum(autocov_series[1:])\n",
    "    cumsum_autocov = np.cumsum(autocov_series[1:])\n",
    "    uncor_variance = autocov_series[0]\n",
    "\n",
    "    forward_cor_variances = np.zeros(len(times))\n",
    "    for i in range(len(times)):\n",
    "        remaining_points = len(times) - i\n",
    "        forward_cor_variances[i] = cumsum_autocov[remaining_points - 1] if remaining_points - 1 < len(cumsum_autocov) else cumsum_autocov[-1]\n",
    "\n",
    "    # Backward correlations are just the same as forward correlations, but in reverse,\n",
    "    # so simply double and add uncorrelated variance\n",
    "    return np.mean(2*forward_cor_variances + uncor_variance)\n",
    "\n",
    "def compute_sem(times: np.ndarray,\n",
    "                autocov_series: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Compute the standard error of the mean for the given times. It is assumed\n",
    "    that the times passed represent the entire series, with same frequency as the \n",
    "    original data.\n",
    "    \"\"\"\n",
    "    sems = np.zeros(len(times))\n",
    "    for i, _ in tqdm(enumerate(times), total=len(times), desc=\"Processing Times\"):\n",
    "        variance = compute_mean_variance(times[i:], autocov_series)\n",
    "        n_points = len(times) - i\n",
    "        sems[i] = np.sqrt(variance / n_points)\n",
    "    return sems\n",
    "\n",
    "def compute_rmse(times: np.ndarray,\n",
    "                 exp_params: tuple[float, float],\n",
    "                 fast_exp_params: tuple[float, float],\n",
    "                 autocov_series: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Compute the RMSE at each time given the exponential parameters. It is\n",
    "    assumed that the times passed represent the entire series, and the number of\n",
    "    data points are the same as those sampled originally.\n",
    "    \"\"\"\n",
    "    bias = compute_bias(times, exp_params, fast_exp_params)\n",
    "    sem = compute_sem(times, autocov_series)\n",
    "    return np.sqrt(sem ** 2 + bias ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the bias, SEM, and RMSE for each dataset\n",
    "fixed_trunc_error_series = {}\n",
    "\n",
    "# Currently, only compute for the standard results\n",
    "for dataset in datasets:\n",
    "    fixed_trunc_error_series[dataset] = {}\n",
    "    for system in systems:\n",
    "        fixed_trunc_error_series[dataset][system] = {}\n",
    "\n",
    "        # Get the parameters used to generate the series\n",
    "        exp_params = params[system][\"exp_params\"]\n",
    "        fast_exp_params = params[system][\"fast_exp_params\"]\n",
    "        variance_fac = 1 if dataset != \"noisy\" else 5\n",
    "        autocov_series = params[system][\"autocov_convex\"] * variance_fac\n",
    "\n",
    "        # If this is the subsampled dataset, them subsample the autocovariance series to account for this\n",
    "        autocov_series = autocov_series[::100] if dataset == \"subsampled\" else autocov_series\n",
    "\n",
    "        # If the dataset is block averaged, the stats are the same as the standard dataset\n",
    "        dataset_lookup = dataset if dataset != \"block_averaged\" else \"standard\"\n",
    "        test_data = data[dataset_lookup][system][0][\"data\"]\n",
    "        tot_time = 8 if dataset != \"short\" else 0.2\n",
    "        times = np.linspace(0, tot_time, len(test_data) + 1)[1:] # The times at which the data were sampled\n",
    "\n",
    "        # Compute the bias, sem, and rmse\n",
    "        bias = compute_bias(times, exp_params, fast_exp_params)\n",
    "        sem = compute_sem(times, autocov_series)\n",
    "        rmse = np.sqrt(sem ** 2 + bias ** 2)\n",
    "\n",
    "        # Get the optimal truncation point\n",
    "        trunc_point = np.argmin(rmse)\n",
    "        trunc_time = times[trunc_point]\n",
    "\n",
    "        # If this is block averaged data, then we need to downsample the series\n",
    "        if dataset == \"block_averaged\":\n",
    "            # Blocks of size 100, ignoring the time closest to 0\n",
    "            bias = bias[::100][1:]\n",
    "            sem = sem[::100][1:]\n",
    "            rmse = rmse[::100][1:]\n",
    "        \n",
    "        assert len(sem) == len(data[dataset][system][0][\"data\"]), f\"Length of SEM series {len(sem)} does not match length of data {len(data[dataset][system][0]['data'])}\"\n",
    "\n",
    "        # Save the results\n",
    "        fixed_trunc_error_series[dataset][system][\"bias_series\"] = bias\n",
    "        fixed_trunc_error_series[dataset][system][\"sem_series\"] = sem\n",
    "        fixed_trunc_error_series[dataset][system][\"rmse_series\"] = rmse\n",
    "        fixed_trunc_error_series[dataset][system][\"optimal_trunc_point\"] = trunc_point\n",
    "        fixed_trunc_error_series[dataset][system][\"optimal_trunc_time\"] = trunc_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"output/fixed_trunc_error_series_stats.pkl\", \"wb\") as f:\n",
    "    pkl.dump(fixed_trunc_error_series, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"output/fixed_trunc_error_series_stats.pkl\", \"rb\") as f:\n",
    "    fixed_trunc_error_series = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_theoretical_rmse_on_axis(ax: Axes, dataset: str, system: str) -> None:\n",
    "    test_data = data[dataset][system][0][\"data\"]\n",
    "    tot_time = 8 if dataset != \"short\" else 0.2\n",
    "    test_times = np.linspace(0, tot_time, len(test_data) + 1)[1:] # The times at which the data was sampled\n",
    "    rmse_series = fixed_trunc_error_series[dataset][system][\"rmse_series\"]\n",
    "\n",
    "    # Get the real RMSE from the discarded fractions\n",
    "    real_rmse = [overall_results[dataset][system][method][\"rmse\"] for method in fixed_methods]\n",
    "    real_cis = [overall_results[dataset][system][method][\"rmse_ci\"] for method in fixed_methods]\n",
    "    cis_lower = abs(np.array(real_cis)[:,0] - np.array(real_rmse))\n",
    "    cis_upper = abs(np.array(real_cis)[:,1] - np.array(real_rmse))\n",
    "    fracs = [float(method.split(\" \")[-1]) for method in fixed_methods]\n",
    "    tot_time = 8 if dataset != \"short\" else 0.2\n",
    "    times = [frac * tot_time for frac in fracs]\n",
    "\n",
    "    # Plot the RMSE\n",
    "    ax.plot(test_times[:], rmse_series[:], label=\"Theoretical\", zorder=2, alpha=0.7)\n",
    "    ax.errorbar(times, real_rmse, yerr=[cis_lower, cis_upper], fmt='-', label=\"Empirical\", zorder=1, ecolor='black')\n",
    "    ax.set_xlabel(\"Truncation Time / ns\")\n",
    "    ax.set_ylabel(\"$\\\\mathrm{RMSE}(\\\\langle \\\\Delta G \\\\rangle_{[n_{0},N]})$ / kcal mol$^{-1}$\")\n",
    "    ax.set_title(system)\n",
    "    \n",
    "    # Set max y limit to be 10 % above the highest RMSE, and 10 % below the lowest RMSE\n",
    "    threshold =np.min(real_rmse[:-1]) * 0.9, np.max(real_rmse[:-1]) * 1.1\n",
    "    ax.set_ylim(*threshold)\n",
    "\n",
    "fig, axs = get_subplots(systems)\n",
    "\n",
    "for i, system in enumerate(systems):\n",
    "    plot_theoretical_rmse_on_axis(axs[i], \"standard\", system)\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "# Only put the legend to the left of the last plot\n",
    "axs[-2].legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "fig.savefig(\"output/theoretical_vs_empirical_rmse.png\", dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_error_components_on_ax(ax: Axes, dataset: str, system: str, show_min: bool = True) -> None:\n",
    "    test_data = data[dataset][system][0][\"data\"]\n",
    "    tot_time = 8 if dataset != \"short\" else 0.2\n",
    "    test_times = np.linspace(0, tot_time, len(test_data) + 1)[1:] # The times at which the data was sampled\n",
    "    bias_series = fixed_trunc_error_series[dataset][system][\"bias_series\"]\n",
    "    sem_series = fixed_trunc_error_series[dataset][system][\"sem_series\"]\n",
    "    rmse_series = fixed_trunc_error_series[dataset][system][\"rmse_series\"]\n",
    "\n",
    "    # Plot the error components, truncating the last 1 % of the data\n",
    "    n_truncate = round(len(test_times) * 0.01) # Truncate the last 1 % of the data to avoid large RMSE scaling the y-axis\n",
    "    ax.plot(test_times[:-(n_truncate + 1)], rmse_series[:-(n_truncate+1)], label=\"$\\\\mathrm{RMSE}(\\\\langle \\\\Delta G \\\\rangle_{[n_{0},N]})$\", zorder=2, alpha=0.7)\n",
    "    ax.plot(test_times[:-(n_truncate + 1)], bias_series[:-(n_truncate+1)], label=\"$\\\\mathrm{Bias}(\\\\langle \\\\Delta G \\\\rangle_{[n_{0},N]})$\", zorder=1, alpha=0.7)\n",
    "    ax.plot(test_times[:-(n_truncate + 1)], sem_series[:-(n_truncate +1)], label=\"$\\\\mathrm{SD}(\\\\langle \\\\Delta G \\\\rangle_{[n_{0},N]})$\", zorder=1, alpha=0.7)\n",
    "    \n",
    "    if show_min:\n",
    "        # Plot dashed vertical line at the optimal truncation point\n",
    "        trunc_time = fixed_trunc_error_series[dataset][system][\"optimal_trunc_time\"]\n",
    "        ax.axvline(trunc_time, color='black', linestyle='--', label=\"Optimal Truncation Time\")\n",
    "\n",
    "        # Plot a dashed horizontal line at the RMSE at the optimal truncation point\n",
    "        trunc_rmse = rmse_series[np.argmin(rmse_series)]\n",
    "        ax.axhline(trunc_rmse, color='black', linestyle='--')\n",
    "\n",
    "        # Add a small red dot at the minimum RMSE\n",
    "        ax.plot(trunc_time, trunc_rmse, 'ro', alpha=0.7)\n",
    "\n",
    "    ax.set_xlabel(\"Truncation Time / ns\")\n",
    "    ax.set_ylabel(\"Error / kcal mol$^{-1}$\")\n",
    "    ax.set_title(system)\n",
    "\n",
    "# Plot the components of the RMSE\n",
    "fig, axs = get_subplots(systems)\n",
    "\n",
    "for i, system in enumerate(systems):\n",
    "    ax = axs[i]\n",
    "    plot_error_components_on_ax(ax, \"standard\", system, show_min=False)\n",
    "    ax.set_xlabel(\"Truncation Time / ns\")\n",
    "    ax.set_ylabel(\"Error / kcal mol$^{-1}$\")\n",
    "    ax.set_title(system)\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "# Only put the legend to the left of the last plot\n",
    "axs[-2].legend(bbox_to_anchor=(1.2, 0.7), loc='upper left')\n",
    "\n",
    "fig.savefig(\"output/error_components.png\", dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Discard Times\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distributions[\"standard\"][\"T4L\"].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_discard_times_on_ax(ax: Axes, dataset: str, system: str, n_truncate: int = 100) -> None:\n",
    "    # Get a dataframe of the times discarded\n",
    "    tot_time = 8 if dataset != \"short\" else 0.2\n",
    "    df_times = pd.DataFrame({method: distributions[dataset][system][method][\"fracs\"]*tot_time for method in automated_methods})\n",
    "    sns.violinplot(data=df_times, ax=ax, orient=\"h\",palette=colors, alpha=1)\n",
    "    ax.set_title(system)\n",
    "    ax.set_xlabel(\"Truncation Time / ns\")\n",
    "\n",
    "    # Plot dashed vertical line at the optimal truncation point\n",
    "    trunc_time = fixed_trunc_error_series[dataset][system][\"optimal_trunc_time\"]\n",
    "    ax.axvline(trunc_time, color='black', linestyle='--', label=\"Optimal Truncation Time\")\n",
    "\n",
    "    ax.set_title(system)\n",
    "\n",
    "# Plot the discard times\n",
    "fig, axs = get_subplots(systems)\n",
    "\n",
    "for i, system in enumerate(systems):\n",
    "    ax = axs[i]\n",
    "    plot_discard_times_on_ax(ax, \"standard\", system, 100)\n",
    "    # Remove y tick labels from right hand column\n",
    "    if i % 2 == 1:\n",
    "        ax.set_yticklabels([])\n",
    "    ax.set_xlabel(\"Truncation Time / ns\")\n",
    "    ax.set_title(system)\n",
    "\n",
    "# Tight layout, but only in the y direction\n",
    "fig.subplots_adjust(hspace=0.5)\n",
    "\n",
    "# Only put the legend to the left of the last plot\n",
    "axs[-2].legend(bbox_to_anchor=(1.2, 0.7), loc='upper left')\n",
    "\n",
    "fig.savefig(\"output/discard_times_standard.png\", dpi=300, bbox_inches='tight')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot RMSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_rmses_on_ax(ax: Axes, dataset: str, system: str, n_truncate: int = 100) -> None:\n",
    "    # Get RMSEs and confidence intervals\n",
    "    rmse = [overall_results[dataset][system][method][\"rmse\"] for method in automated_methods]\n",
    "    cis = [overall_results[dataset][system][method][\"rmse_ci\"] for method in automated_methods]\n",
    "\n",
    "    # Convert CIs from absolute values to relative values\n",
    "    cis_lower = np.array(rmse) - np.array(cis)[:,0]\n",
    "    cis_upper = np.array(cis)[:,1] - np.array(rmse)\n",
    "    error_bar_settings = {\"capsize\": 0, \"alpha\": 1, \"elinewidth\": 1}\n",
    "    ax.bar(automated_methods, rmse, yerr=[cis_lower, cis_upper], capsize=5, \n",
    "           alpha=1, error_kw=error_bar_settings, color=colors, edgecolor='black', linewidth=1)\n",
    "    \n",
    "    # Get the minimum possible fixed-time RMSE and plot a horizontal to show it\n",
    "    min_rmse = np.min(fixed_trunc_error_series[dataset][system][\"rmse_series\"])\n",
    "    ax.axhline(min_rmse, color='black', linestyle='--', label=\"Minimum Fixed-Time RMSE\")\n",
    "\n",
    "    # Plot the 0.2 % discard RMSE\n",
    "    # discard_rmse = overall_results[dataset][system][\"Discard Fraction 0.2\"][\"rmse\"]\n",
    "    # ax.axhline(discard_rmse, color='red', linestyle='--', label=\"Discard Fraction 0.2 RMSE\")\n",
    "\n",
    "    ax.set_xticklabels(methods, rotation=90)\n",
    "    ax.set_title(system)\n",
    "\n",
    "    # Remove x grid ylines\n",
    "    ax.xaxis.grid(False)\n",
    "\n",
    "# Plot the RMSEs\n",
    "fig, axs = get_subplots(systems)\n",
    "\n",
    "for i, system in enumerate(systems):\n",
    "    ax = axs[i]\n",
    "    plot_rmses_on_ax(ax, \"standard\", system, 100)\n",
    "    ax.set_ylabel(\"$\\\\mathrm{RMSE}(\\\\langle \\\\Delta G \\\\rangle)$ \\n/ kcal mol$^{-1}$\")\n",
    "    ax.set_title(system)\n",
    "\n",
    "    # Remove x labels from first 3 plots\n",
    "    if i < 3:\n",
    "        ax.set_xticklabels([])\n",
    "\n",
    "    # Remove y labels from right column\n",
    "    if i % 2 == 1:\n",
    "        ax.set_ylabel(\"\")\n",
    "\n",
    "    # Add the legend to the last plot\n",
    "    if i == len(systems) - 1:\n",
    "        ax.legend(bbox_to_anchor=(1.05, -0.3), loc='upper left')\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "fig.savefig(\"output/rmses_standard.png\", dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distributions of Unsigned Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_unsigned_error_distribution_on_ax(ax: Axes, dataset: str, system: str) -> None:\n",
    "    # Get the squared errors\n",
    "    df_ses = pd.DataFrame({method: distributions[dataset][system][method][\"mues\"] for method in automated_methods})\n",
    "    sns.violinplot(data=df_ses, ax=ax, palette=colors)\n",
    "    ax.set_title(system)\n",
    "    ax.set_ylabel(\"Unsigned Error / kcal mol$^{-1}$\")\n",
    "    ax.set_xticklabels(methods, rotation=90)\n",
    "    \n",
    "    # Get the minimum possible fixed-time RMSE and plot a horizontal to show it\n",
    "    min_rmse = np.min(fixed_trunc_error_series[dataset][system][\"rmse_series\"])\n",
    "    ax.axhline(min_rmse, color='black', linestyle='--', label=\"Minimum Fixed-Time RMSE\")\n",
    "\n",
    "# Plot the squared errors\n",
    "fig, axs = get_subplots(systems)\n",
    "\n",
    "for i, system in enumerate(systems):\n",
    "    ax = axs[i]\n",
    "    plot_unsigned_error_distribution_on_ax(ax, \"standard\", system)\n",
    "    ax.set_title(system)\n",
    "\n",
    "    # Remove x labels from first 3 plots\n",
    "    if i < 3:\n",
    "        ax.set_xticklabels([])\n",
    "\n",
    "    # Remove y labels from right column\n",
    "    if i % 2 == 1:\n",
    "        ax.set_ylabel(\"\")\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "fig.savefig(\"output/unsigned_errors_standard.png\", dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contour Plots of Components of Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on the code above\n",
    "def plot_contour_plot_on_axis(ax: Axes, dataset: str, system: str) -> None:\n",
    "    # Get the fixed-time bias and sem\n",
    "    bias = fixed_trunc_error_series[dataset][system][\"bias_series\"]\n",
    "    sem = fixed_trunc_error_series[dataset][system][\"sem_series\"]\n",
    "    ax.plot(bias, sem, label=\"Fixed Truncation\\n Time Limit\", zorder=2)\n",
    "\n",
    "    # Now, get the biases, variances, and associated CIs for all of the methods.\n",
    "    # We need these to decide how big the grid needs to be\n",
    "    biases = [overall_results[dataset][system][method][\"bias\"] for method in automated_methods]\n",
    "    sems = [overall_results[dataset][system][method][\"variance\"]**0.5 for method in automated_methods]\n",
    "    bias_cis_upper = [overall_results[dataset][system][method][\"mean_ci\"][1] - overall_results[dataset][system][method][\"bias\"] for method in automated_methods]\n",
    "    bias_cis_lower = [overall_results[dataset][system][method][\"bias\"] - overall_results[dataset][system][method][\"mean_ci\"][0] for method in automated_methods]\n",
    "    sem_cis_upper = [overall_results[dataset][system][method][\"var_ci\"][1]**0.5 - overall_results[dataset][system][method][\"variance\"]**0.5 for method in automated_methods]\n",
    "    sem_cis_lower = [overall_results[dataset][system][method][\"variance\"]**0.5 - overall_results[dataset][system][method][\"var_ci\"][0]**0.5 for method in automated_methods]\n",
    "\n",
    "    # Create a grid of points\n",
    "    max_bias_or_sem = max(max(biases), max(sems))\n",
    "    limit = max_bias_or_sem + max_bias_or_sem * 0.1\n",
    "    x = np.linspace(-limit, limit, 1000)\n",
    "    y = np.linspace(-limit, limit, 1000)\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "\n",
    "    # Calculate distance from origin\n",
    "    Z = np.sqrt(X**2 + Y**2)\n",
    "\n",
    "    # Create a contour plot so that there are 10 contours\n",
    "    d_error = limit / 8\n",
    "    # Round error steps up to nearest 0.05 kcal/mol\n",
    "    # d_error = np.ceil(d_error / 0.05) * 0.05\n",
    "    d_error = round(d_error, 2)\n",
    "    contour_levels = np.arange(0, np.max(Z), d_error)\n",
    "    contourf = ax.contourf(X, Y, Z, levels=contour_levels, cmap='viridis')\n",
    "\n",
    "    # Add on the equilibration detection results\n",
    "    for i, method in enumerate(automated_methods):\n",
    "        ax.errorbar(biases[i], sems[i], xerr=[[bias_cis_lower[i]], [bias_cis_upper[i]]], yerr=[[sem_cis_lower[i]], [sem_cis_upper[i]]], \n",
    "                                              fmt='none', ecolor='black', capsize=5, markerfacecolor='white', zorder=1)\n",
    "\n",
    "        ax.scatter(biases[i], sems[i], label=method, edgecolors='black', linewidth=1, s=50, zorder=2, color=colors[i])\n",
    "\n",
    "    # Set x and y limits\n",
    "    negative_limit = -limit * 0.02\n",
    "    ax.set_xlim([negative_limit, limit])\n",
    "    ax.set_ylim([negative_limit, limit])\n",
    "\n",
    "    # Add a horizontal colour bar below the plot\n",
    "    cbar = plt.colorbar(contourf, orientation='horizontal', location='top')\n",
    "    cbar.set_label(\"$\\\\mathrm{RMSE}(\\\\langle \\\\Delta G \\\\rangle )$ / kcal mol$^{-1}$\")\n",
    "\n",
    "    # Set x and y labels, and force aspect ratio to be equal\n",
    "    ax.set_xlabel(\"$\\\\langle \\\\mathrm{Bias}(\\\\langle \\\\Delta G \\\\rangle) \\\\rangle$ / kcal mol$^{-1}$\")\n",
    "    ax.set_ylabel(\"$\\\\mathrm{SD}(\\\\langle \\\\Delta G \\\\rangle)$ / kcal mol$^{-1}$\")\n",
    "    ax.set_aspect('equal', adjustable='box')\n",
    "\n",
    "# Plot the contour plots\n",
    "fig, axs = get_subplots(systems, scale_y=1.2)\n",
    "\n",
    "for i, system in enumerate(systems):\n",
    "    ax = axs[i]\n",
    "    plot_contour_plot_on_axis(ax, \"standard\", system)\n",
    "    ax.set_title(system, pad=60)\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "# Set the legend on the last plot\n",
    "axs[-2].legend(loc='center left', bbox_to_anchor=(1.1, 0.5))\n",
    "\n",
    "fig.savefig(\"output/bias_vs_sem_contour_plots.png\", dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overall Plots\n",
    "\n",
    "Combine the plots of error components, discard times, and RMSEs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a grid of 5 sections, one for each system. For each section, create a grid of 4 plots.\n",
    "\n",
    "fig = plt.figure(figsize=(30, 6))\n",
    "\n",
    "# Gridspec with 2 rows and 10 columns\n",
    "# gs_outer = gridspec.GridSpec(1, 5, figure=fig)\n",
    "subfigs = fig.subfigures(1, 5)\n",
    "\n",
    "axs = []\n",
    "for i, system in enumerate(systems):\n",
    "\n",
    "    # Get subfigure, grid spec, and add title\n",
    "    subfig = subfigs[i]\n",
    "    gs = gridspec.GridSpec(2, 2, figure=subfig, hspace=0.05, wspace=0.05)\n",
    "    subfig.suptitle(system, fontsize=16, fontweight='bold')\n",
    "\n",
    "    # Create subplots with axes shared as required\n",
    "    components_ax = subfig.add_subplot(gs[1,0])\n",
    "    discard_ax = subfig.add_subplot(gs[0,0], sharex=components_ax)\n",
    "    rmse_ax = subfig.add_subplot(gs[1,1], sharey=components_ax)\n",
    "    unused_ax = subfig.add_subplot(gs[0,1])\n",
    "    \n",
    "    # Plot/ delete axes\n",
    "    plot_error_components_on_ax(components_ax, \"standard\", system, 100)\n",
    "    plot_discard_times_on_ax(discard_ax, \"standard\", system, 100)\n",
    "    plot_rmses_on_ax(rmse_ax, \"standard\", system, 100)\n",
    "    subfig.delaxes(unused_ax)\n",
    "\n",
    "    # Remove unnecessary labels/ titles\n",
    "    components_ax.set_title(\"\")\n",
    "    if i == 0:\n",
    "        components_ax.legend(bbox_to_anchor=(-0.05, -0.3), loc='upper left')\n",
    "    rmse_ax.set_title(\"$\\\\mathrm{RMSE}(\\\\langle \\\\Delta G \\\\rangle)$\")\n",
    "    rmse_ax.set_ylabel(\"\")\n",
    "    discard_ax.set_title(\"Truncation Time\")\n",
    "    discard_ax.set_xlabel(\"\")\n",
    "    # Hide the numbers on the x axis for the discard times plot, but don't set labels to empty as this effects the RMSE plot\n",
    "    discard_ax.tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False)\n",
    "    rmse_ax.tick_params(axis='y', which='both', left=False, right=False, labelleft=False)\n",
    "    \n",
    "    # If this isn't the first system, remove the labels from the discard times plot\n",
    "    if i != 0:\n",
    "        discard_ax.set_yticklabels([])\n",
    "        \n",
    "\n",
    "fig.savefig(\"output/combined_plots.png\", dpi=300, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a grid of 5 sections, one for each system. For each section, create a grid of 4 plots.\n",
    "\n",
    "fig = plt.figure(figsize=(21, 14))\n",
    "\n",
    "# Gridspec with 2 rows and 10 columns\n",
    "# gs_outer = gridspec.GridSpec(1, 5, figure=fig)\n",
    "subfigs = fig.subfigures(2, 3)\n",
    "subfigs = subfigs.flatten()\n",
    "\n",
    "axs = []\n",
    "for i, system in enumerate(systems):\n",
    "\n",
    "    # Get subfigure, grid spec, and add title\n",
    "    subfig = subfigs[i]\n",
    "    gs = gridspec.GridSpec(2, 2, figure=subfig, hspace=0.05, wspace=0.05)\n",
    "    subfig.suptitle(system, fontsize=16, fontweight='bold')\n",
    "\n",
    "    # Create subplots with axes shared as required\n",
    "    components_ax = subfig.add_subplot(gs[1,0])\n",
    "    discard_ax = subfig.add_subplot(gs[0,0], sharex=components_ax)\n",
    "    rmse_ax = subfig.add_subplot(gs[1,1], sharey=components_ax)\n",
    "    unused_ax = subfig.add_subplot(gs[0,1])\n",
    "    \n",
    "    # Plot/ delete axes\n",
    "    plot_error_components_on_ax(components_ax, \"standard\", system, 100)\n",
    "    plot_discard_times_on_ax(discard_ax, \"standard\", system, 100)\n",
    "    plot_rmses_on_ax(rmse_ax, \"standard\", system, 100)\n",
    "    subfig.delaxes(unused_ax)\n",
    "\n",
    "    # Remove unnecessary labels/ titles\n",
    "    components_ax.set_title(\"\")\n",
    "    if i == 2:\n",
    "        components_ax.legend(bbox_to_anchor=(0.05, -0.5), loc='upper left')\n",
    "\n",
    "    # Remove x labels from first two plots\n",
    "    if i < 2:\n",
    "        rmse_ax.set_xticklabels([])\n",
    "\n",
    "    rmse_ax.set_title(\"$\\\\mathrm{RMSE}(\\\\langle \\\\Delta G \\\\rangle)$\")\n",
    "    rmse_ax.set_ylabel(\"\")\n",
    "    discard_ax.set_title(\"Truncation Time\")\n",
    "    discard_ax.set_xlabel(\"\")\n",
    "    # Hide the numbers on the x axis for the discard times plot, but don't set labels to empty as this effects the RMSE plot\n",
    "    discard_ax.tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False)\n",
    "    rmse_ax.tick_params(axis='y', which='both', left=False, right=False, labelleft=False)\n",
    "    \n",
    "    # If this isn't the first system in a row, remove the labels from the discard times plot\n",
    "    if i not in [0, 3]:\n",
    "        discard_ax.set_yticklabels([])\n",
    "        \n",
    "\n",
    "fig.savefig(\"output/combined_plots_reformatted.png\", dpi=300, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat above plot, but show distributions of unsigned\n",
    "# errors instead of RMSE of dataset\n",
    "\n",
    "fig = plt.figure(figsize=(30, 6))\n",
    "\n",
    "# Gridspec with 2 rows and 10 columns\n",
    "# gs_outer = gridspec.GridSpec(1, 5, figure=fig)\n",
    "subfigs = fig.subfigures(1, 5)\n",
    "\n",
    "axs = []\n",
    "for i, system in enumerate(systems):\n",
    "\n",
    "    # Get subfigure, grid spec, and add title\n",
    "    subfig = subfigs[i]\n",
    "    gs = gridspec.GridSpec(2, 2, figure=subfig, hspace=0.05, wspace=0.05)\n",
    "    subfig.suptitle(system, fontsize=16, fontweight='bold')\n",
    "\n",
    "    # Create subplots with axes shared as required\n",
    "    components_ax = subfig.add_subplot(gs[1,0])\n",
    "    discard_ax = subfig.add_subplot(gs[0,0], sharex=components_ax)\n",
    "    rmse_ax = subfig.add_subplot(gs[1,1], sharey=components_ax)\n",
    "    unused_ax = subfig.add_subplot(gs[0,1])\n",
    "    \n",
    "    # Plot/ delete axes\n",
    "    plot_error_components_on_ax(components_ax, \"standard\", system, 100)\n",
    "    plot_discard_times_on_ax(discard_ax, \"standard\", system, 100)\n",
    "    plot_unsigned_error_distribution_on_ax(rmse_ax, \"standard\", system)\n",
    "    subfig.delaxes(unused_ax)\n",
    "\n",
    "    # Remove unnecessary labels/ titles\n",
    "    components_ax.set_title(\"\")\n",
    "    if i == 0:\n",
    "        components_ax.legend(bbox_to_anchor=(-0.05, -0.3), loc='upper left')\n",
    "    rmse_ax.set_title(\"Unsigned Errors\")\n",
    "    rmse_ax.set_ylabel(\"\")\n",
    "    discard_ax.set_title(\"Time Discarded\")\n",
    "    discard_ax.set_xlabel(\"\")\n",
    "    # Hide the numbers on the x axis for the discard times plot, but don't set labels to empty as this effects the RMSE plot\n",
    "    discard_ax.tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False)\n",
    "    rmse_ax.tick_params(axis='y', which='both', left=False, right=False, labelleft=False)\n",
    "    \n",
    "    # If this isn't the first system, remove the labels from the discard times plot\n",
    "    if i != 0:\n",
    "        discard_ax.set_yticklabels([])\n",
    "        \n",
    "\n",
    "fig.savefig(\"output/combined_plots_unsigned_errors.png\", dpi=300, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Plots for All Datasets\n",
    "\n",
    "Redo the above plots, but show results for all datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, let's define a function to supply a nice set of axes\n",
    "def get_subplots_all_datasets(systems: list[str], datasets: list[str], scale_x: float = 1, scale_y: float = 1) -> tuple[plt.Figure, list[plt.Axes]]:\n",
    "    # We want the same number of columns as systems, and the same number of rows as datasets\n",
    "    n_cols = len(systems)\n",
    "    n_rows = len(datasets)\n",
    "    return plt.subplots(n_rows, n_cols, figsize=(scale_x*3 * n_cols, scale_y*3*n_rows))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, let's plot the RMSEs for all datasets\n",
    "fig, axs = get_subplots_all_datasets(systems, datasets)\n",
    "\n",
    "for i, dataset in enumerate(datasets):\n",
    "    for j, system in enumerate(systems):\n",
    "        ax = axs[i, j]\n",
    "        plot_theoretical_rmse_on_axis(ax, dataset, system)\n",
    "        ax.set_title(sanitise_name(f\"{system}\\n{dataset}\"))\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "middle_bottom_ax = axs[4, 2]\n",
    "middle_bottom_ax.legend(bbox_to_anchor=(0.1, -0.4), loc='upper left')\n",
    "\n",
    "fig.savefig(\"output/theoretical_vs_empirical_rmse_all_datasets.png\", dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat, but this time for the error components\n",
    "\n",
    "fig, axs = get_subplots_all_datasets(systems, datasets)\n",
    "\n",
    "for i, dataset in enumerate(datasets):\n",
    "    for j, system in enumerate(systems):\n",
    "        ax = axs[i, j]\n",
    "        plot_error_components_on_ax(ax, dataset, system, show_min=True)\n",
    "        ax.set_title(sanitise_name(f\"{system} \\n {dataset}\"))\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "middle_bottom_ax = axs[4, 2]\n",
    "middle_bottom_ax.legend(bbox_to_anchor=(0.1, -0.4), loc='upper left')\n",
    "\n",
    "fig.savefig(\"output/error_components_all_datasets.png\", dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat, but this time for the discard times\n",
    "\n",
    "fig, axs = get_subplots_all_datasets(systems, datasets)\n",
    "\n",
    "for i, dataset in enumerate(datasets):\n",
    "    for j, system in enumerate(systems):\n",
    "        ax = axs[i, j]\n",
    "        plot_discard_times_on_ax(ax, dataset, system, 100)\n",
    "        ax.set_title(sanitise_name(f\"{system} \\n {dataset}\"))\n",
    "\n",
    "        # Remove labels unless in left-most column\n",
    "        if j != 0:\n",
    "            ax.set_yticklabels([])\n",
    "\n",
    "        # Rmove x axis label unless on bottom row\n",
    "        if i != len(datasets) - 1:\n",
    "            ax.set_xlabel(\"\")\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "middle_bottom_ax = axs[4, 2]\n",
    "middle_bottom_ax.legend(bbox_to_anchor=(0.1, -0.4), loc='upper left')\n",
    "\n",
    "fig.savefig(\"output/discard_times_all_datasets.png\", dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the RMSEs for all datasets\n",
    "\n",
    "fig, axs = get_subplots_all_datasets(systems, datasets)\n",
    "\n",
    "for i, dataset in enumerate(datasets):\n",
    "    for j, system in enumerate(systems):\n",
    "        ax = axs[i, j]\n",
    "        plot_rmses_on_ax(ax, dataset, system, 100)\n",
    "        ax.set_title(sanitise_name(f\"{system} \\n {dataset}\"))\n",
    "\n",
    "        # Remove x tick labels unless in bottom row\n",
    "        if i != len(datasets) - 1:\n",
    "            ax.set_xticklabels([])\n",
    "\n",
    "        # Only add y axis label to left-most column\n",
    "        if j == 0:\n",
    "            ax.set_ylabel(\"$\\\\mathrm{RMSE}(\\\\langle \\\\Delta G \\\\rangle)$ / kcal mol$^{-1}$\")\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "middle_bottom_ax = axs[4, 2]\n",
    "middle_bottom_ax.legend(bbox_to_anchor=(0.1, -1.7), loc='upper left')\n",
    "\n",
    "fig.savefig(\"output/rmses_all_datasets.png\", dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unsigned errors\n",
    "\n",
    "fig, axs = get_subplots_all_datasets(systems, datasets)\n",
    "\n",
    "for i, dataset in enumerate(datasets):\n",
    "    for j, system in enumerate(systems):\n",
    "        ax = axs[i, j]\n",
    "        plot_unsigned_error_distribution_on_ax(ax, dataset, system)\n",
    "        ax.set_title(sanitise_name(f\"{system} \\n {dataset}\"))\n",
    "\n",
    "        # Remove x tick labels unless in bottom row\n",
    "        if i != len(datasets) - 1:\n",
    "            ax.set_xticklabels([])\n",
    "\n",
    "        # Only add y axis label to left-most column\n",
    "        if j == 0:\n",
    "            ax.set_ylabel(\"Unsigned Error / kcal mol$^{-1}$\")\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "middle_bottom_ax = axs[4, 2]\n",
    "middle_bottom_ax.legend(bbox_to_anchor=(0.1, -1.7), loc='upper left')\n",
    "\n",
    "fig.savefig(\"output/unsigned_errors_all_datasets.png\", dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contour plots\n",
    "\n",
    "fig, axs = get_subplots_all_datasets(systems, datasets, scale_y = 1.2)\n",
    "\n",
    "for i, dataset in enumerate(datasets):\n",
    "    for j, system in enumerate(systems):\n",
    "        ax = axs[i, j]\n",
    "        plot_contour_plot_on_axis(ax, dataset, system)\n",
    "        ax.set_title(sanitise_name(f\"{system} \\n {dataset}\"), pad=60)\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "middle_bottom_ax = axs[4, 2]\n",
    "middle_bottom_ax.legend(bbox_to_anchor=(-0.2, -0.4), loc='upper left')\n",
    "\n",
    "fig.savefig(\"output/bias_vs_sem_contour_plots_all_datasets.png\", dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall plots for all datasets\n",
    "\n",
    "fig = plt.figure(figsize=(30, 30))\n",
    "\n",
    "subfigs = fig.subfigures(5, 5)\n",
    "\n",
    "axs = []\n",
    "for j, dataset in enumerate(datasets):\n",
    "    for i, system in enumerate(systems):\n",
    "\n",
    "        # Get subfigure, grid spec, and add title\n",
    "        subfig = subfigs[j, i]\n",
    "        gs = gridspec.GridSpec(2, 2, figure=subfig, hspace=0.05, wspace=0.05)\n",
    "        subfig.suptitle(sanitise_name(f\"{system} \\n {dataset}\"), fontsize=16, fontweight='bold')\n",
    "\n",
    "        # Create subplots with axes shared as required\n",
    "        components_ax = subfig.add_subplot(gs[1,0])\n",
    "        discard_ax = subfig.add_subplot(gs[0,0], sharex=components_ax)\n",
    "        rmse_ax = subfig.add_subplot(gs[1,1], sharey=components_ax)\n",
    "        unused_ax = subfig.add_subplot(gs[0,1])\n",
    "        \n",
    "        # Plot/ delete axes\n",
    "        plot_error_components_on_ax(components_ax, dataset, system)\n",
    "        plot_discard_times_on_ax(discard_ax, dataset, system)\n",
    "        plot_rmses_on_ax(rmse_ax, dataset, system)\n",
    "        subfig.delaxes(unused_ax)\n",
    "\n",
    "        # Remove unnecessary labels/ titles\n",
    "        components_ax.set_title(\"\")\n",
    "        if i == 0 and j ==4:\n",
    "            components_ax.legend(bbox_to_anchor=(-0.05, -0.3), loc='upper left')\n",
    "        rmse_ax.set_title(\"$\\\\mathrm{RMSE}(\\\\langle \\\\Delta G \\\\rangle)$\")\n",
    "        rmse_ax.set_ylabel(\"\")\n",
    "        discard_ax.set_title(\"Truncation Time\")\n",
    "        discard_ax.set_xlabel(\"\")\n",
    "\n",
    "        # Remove the RMSE bar plot tick labels unless this is the bottom row\n",
    "        if j != 4:\n",
    "            rmse_ax.set_xticklabels([])\n",
    "\n",
    "        # Hide the numbers on the x axis for the discard times plot, but don't set labels to empty as this effects the RMSE plot\n",
    "        discard_ax.tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False)\n",
    "        rmse_ax.tick_params(axis='y', which='both', left=False, right=False, labelleft=False)\n",
    "        \n",
    "        # If this isn't the first system, remove the labels from the discard times plot\n",
    "        if i != 0:\n",
    "            discard_ax.set_yticklabels([])\n",
    "        \n",
    "\n",
    "fig.savefig(\"output/combined_plots_all_datasets.png\", dpi=300, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall plots for all datasets\n",
    "\n",
    "fig = plt.figure(figsize=(30, 30))\n",
    "\n",
    "subfigs = fig.subfigures(5, 5)\n",
    "\n",
    "axs = []\n",
    "for j, dataset in enumerate(datasets):\n",
    "    for i, system in enumerate(systems):\n",
    "\n",
    "        # Get subfigure, grid spec, and add title\n",
    "        subfig = subfigs[j, i]\n",
    "        gs = gridspec.GridSpec(2, 2, figure=subfig, hspace=0.05, wspace=0.05)\n",
    "        subfig.suptitle(sanitise_name(f\"{system} \\n {dataset}\"), fontsize=16, fontweight='bold')\n",
    "\n",
    "        # Create subplots with axes shared as required\n",
    "        components_ax = subfig.add_subplot(gs[1,0])\n",
    "        discard_ax = subfig.add_subplot(gs[0,0], sharex=components_ax)\n",
    "        rmse_ax = subfig.add_subplot(gs[1,1], sharey=components_ax)\n",
    "        unused_ax = subfig.add_subplot(gs[0,1])\n",
    "        \n",
    "        # Plot/ delete axes\n",
    "        plot_error_components_on_ax(components_ax, dataset, system)\n",
    "        plot_discard_times_on_ax(discard_ax, dataset, system)\n",
    "        plot_unsigned_error_distribution_on_ax(rmse_ax, \"standard\", system)\n",
    "        subfig.delaxes(unused_ax)\n",
    "\n",
    "        # Remove unnecessary labels/ titles\n",
    "        components_ax.set_title(\"\")\n",
    "        if i == 0 and j ==4:\n",
    "            components_ax.legend(bbox_to_anchor=(-0.05, -0.3), loc='upper left')\n",
    "        rmse_ax.set_title(\"$\\\\mathrm{RMSE}(\\\\langle \\\\Delta G \\\\rangle)$\")\n",
    "        rmse_ax.set_ylabel(\"\")\n",
    "        discard_ax.set_title(\"Truncation Time\")\n",
    "        discard_ax.set_xlabel(\"\")\n",
    "\n",
    "        # Remove the RMSE bar plot tick labels unless this is the bottom row\n",
    "        if j != 4:\n",
    "            rmse_ax.set_xticklabels([])\n",
    "\n",
    "        # Hide the numbers on the x axis for the discard times plot, but don't set labels to empty as this effects the RMSE plot\n",
    "        discard_ax.tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False)\n",
    "        rmse_ax.tick_params(axis='y', which='both', left=False, right=False, labelleft=False)\n",
    "        \n",
    "        # If this isn't the first system, remove the labels from the discard times plot\n",
    "        if i != 0:\n",
    "            discard_ax.set_yticklabels([])\n",
    "        \n",
    "\n",
    "fig.savefig(\"output/combined_plots_all_datasets_unsigned_errors.png\", dpi=300, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat for the discard times\n",
    "\n",
    "fig, axs = get_subplots_all_datasets(systems, datasets)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example systems list\n",
    "systems = ['System 1', 'System 2', 'System 3', 'System 4', 'System 5']\n",
    "\n",
    "# Create a figure\n",
    "fig = plt.figure(figsize=(30, 12))\n",
    "\n",
    "# Create a mosaic layout\n",
    "mosaic = \"\"\"\n",
    "AABBCCDDEE\n",
    "AABBCCDDff\n",
    "\"\"\"\n",
    "\n",
    "# Create subplots using subplot_mosaic\n",
    "ax_dict = fig.subplot_mosaic(mosaic, gridspec_kw={'hspace': 0.4, 'wspace': 0.4})\n",
    "\n",
    "# Create subplots for each section\n",
    "axs = []\n",
    "for i, system in enumerate(systems):\n",
    "    # Calculate the starting column index for each section\n",
    "    col_start = i * 2\n",
    "\n",
    "    # Create subplots with axes shared as required\n",
    "    components_ax = ax_dict[f'{chr(65 + i)}B']\n",
    "    discard_ax = ax_dict[f'{chr(65 + i)}A']\n",
    "    rmse_ax = ax_dict[f'{chr(65 + i)}D']\n",
    "    unused_ax = ax_dict[f'{chr(65 + i)}C']\n",
    "    \n",
    "    # Add all the axes to the list\n",
    "    axs.append([discard_ax, components_ax, rmse_ax])\n",
    "\n",
    "    # Plot/delete axes\n",
    "    plot_error_components_on_ax(components_ax, \"standard\", system, 100)\n",
    "    plot_discard_times_on_ax(discard_ax, \"standard\", system, 100)\n",
    "    plot_rmses_on_ax(rmse_ax, \"standard\", system, 100)\n",
    "    fig.delaxes(unused_ax)\n",
    "\n",
    "    # Remove unnecessary labels/titles\n",
    "    components_ax.set_title(\"\")\n",
    "    rmse_ax.set_title(\"\")\n",
    "    rmse_ax.set_ylabel(\"\")\n",
    "    discard_ax.set_xlabel(\"\")\n",
    "    # Hide the numbers on the x axis for the discard times plot, but don't set labels to empty as this affects the RMSE plot\n",
    "    discard_ax.tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False)\n",
    "    rmse_ax.tick_params(axis='y', which='both', left=False, right=False, labelleft=False)\n",
    "\n",
    "    # If this isn't the first system, remove the labels from the discard times plot\n",
    "    if i != 0:\n",
    "        discard_ax.set_yticklabels([])\n",
    "\n",
    "    # Add a title for each section\n",
    "    fig.text(0.5, 0.5 - i * 0.2, f'System: {system}', ha='center', va='center', fontsize=16, transform=fig.transFigure)\n",
    "\n",
    "# Adjust the layout\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linspace(1,4,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_results[\"block_averaged\"][\"MIF\"][\"Uncorrelated Estimate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot bar plots of the RMSE for MIF only\n",
    "# Make a plot for each dataset (5)\n",
    "\n",
    "def get_subplots(systems: list[str]) -> tuple[plt.Figure, list[plt.Axes]]:\n",
    "    # Plot two columns side-by-side\n",
    "    n_cols = min(2, len(systems))\n",
    "    n_rows = int(np.ceil(len(systems) / n_cols))\n",
    "    # fig, axs = plt.subplots(n_rows, n_cols, figsize=(3 * n_cols, 5*n_rows))\n",
    "    fig, axs = plt.subplots(n_rows, n_cols, figsize=(3 * n_cols, 3*n_rows))\n",
    "    if len(systems) == 1:\n",
    "        axs = [axs]\n",
    "    else:\n",
    "        axs = axs.flatten()\n",
    "\n",
    "    # Set titles\n",
    "    for i, system in enumerate(systems):\n",
    "        axs[i].set_title(system)\n",
    "\n",
    "    # Remove any unused axes\n",
    "    for i in range(len(systems), len(axs)):\n",
    "        fig.delaxes(axs[i])\n",
    "\n",
    "    return fig, axs\n",
    "\n",
    "automated_methods = [method for method in methods if \"Discard\" not in method]\n",
    "fixed_methods = [method for method in methods if \"Discard\" in method]\n",
    "fig, axs = get_subplots(datasets)\n",
    "\n",
    "# For MIF only, plot the RMSE for each dataset with a bar plot on a new axis.\n",
    "SYSTEM = \"MIF\"\n",
    "\n",
    "for i, dataset in enumerate(datasets):\n",
    "    ax = axs[i]\n",
    "    rmse = [overall_results[dataset][SYSTEM][method][\"rmse\"] for method in automated_methods]\n",
    "    cis = [overall_results[dataset][SYSTEM][method][\"rmse_ci\"] for method in automated_methods]\n",
    "    # Convert CIs from absolute values to relative values\n",
    "    cis_lower = abs(np.array(cis)[:,0] - np.array(rmse))\n",
    "    cis_upper = abs(np.array(cis)[:,1] - np.array(rmse))\n",
    "    ax.bar(automated_methods, rmse, yerr=[cis_lower, cis_upper], capsize=5)\n",
    "    # Rotate labels 90 degrees\n",
    "    ax.set_xticklabels(methods, rotation=90)\n",
    "    ax.set_ylabel(\"RMSE / kcal mol$^{-1}$\")\n",
    "    ax.set_title(dataset)\n",
    "\n",
    "    # Remove x labels from first 3 plots\n",
    "    if i < 3:\n",
    "        ax.set_xticklabels([])\n",
    "\n",
    "    # Remove y labels from right column\n",
    "    if i % 2 == 1:\n",
    "        ax.set_ylabel(\"\")\n",
    "\n",
    "# Stop the long labels overlapping\n",
    "fig.subplots_adjust(wspace=0.3)\n",
    "fig.savefig(f\"output/rmse_bar_plots_{SYSTEM.lower()}.png\", dpi=300, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As above, but plot all datasets on the same plot\n",
    "\n",
    "DATASET = \"standard\"\n",
    "\n",
    "fig, axs = get_subplots(systems)\n",
    "\n",
    "# For MIF only, plot the RMSE for each dataset with a bar plot on a new axis.\n",
    "for i, system in enumerate(systems):\n",
    "    ax = axs[i]\n",
    "    rmse = [overall_results[DATASET][system][method][\"rmse\"] for method in automated_methods]\n",
    "    cis = [overall_results[DATASET][system][method][\"rmse_ci\"] for method in automated_methods]\n",
    "\n",
    "    # Convert CIs from absolute values to relative values\n",
    "    cis_lower = abs(np.array(cis)[:,0] - np.array(rmse))\n",
    "    cis_upper = abs(np.array(cis)[:,1] - np.array(rmse))\n",
    "    ax.bar(automated_methods, rmse, yerr=[cis_lower, cis_upper], capsize=5, alpha=0.7, label=system)\n",
    "\n",
    "    # Rotate labels 90 degrees\n",
    "    ax.set_xticklabels(methods, rotation=90)\n",
    "    ax.set_ylabel(\"RMSE / kcal mol$^{-1}$\")\n",
    "    ax.set_title(system)\n",
    "\n",
    "    # Get the lowest RMSE from any fixed-time method\n",
    "    fixed_rmse = [overall_results[DATASET][system][method][\"rmse\"] for method in fixed_methods]\n",
    "    # Get the name of the lowest RMSE method\n",
    "    best_fixed_method = fixed_methods[np.argmin(fixed_rmse[:-1])]\n",
    "    ax.axhline(min(fixed_rmse), color=\"red\", linestyle=\"--\")\n",
    "    # Add text with the best fixed-time method\n",
    "    # ax.text(0.5, min(fixed_rmse), f\"Best fixed-time method: {best_fixed_method}\", ha=\"center\", va=\"bottom\")\n",
    "\n",
    "    # Plot a blue line at the RMSE of the 0.1 fraction discarded method and 0.4 fraction discarded method\n",
    "    rmse_01 = overall_results[DATASET][system][\"Discard Fraction 0.1\"][\"rmse\"]\n",
    "    rmse_04 = overall_results[DATASET][system][\"Discard Fraction 0.4\"][\"rmse\"]\n",
    "    ax.axhline(rmse_01, color=\"blue\", linestyle=\"--\")\n",
    "    ax.axhline(rmse_04, color=\"green\", linestyle=\"--\")\n",
    "\n",
    "    \n",
    "\n",
    "    # Remove x labels from first 3 plots\n",
    "    if i < 3:\n",
    "        ax.set_xticklabels([])\n",
    "\n",
    "    # Remove y labels from right column\n",
    "    if i % 2 == 1:\n",
    "        ax.set_ylabel(\"\")\n",
    "\n",
    "# Stop the long labels overlapping\n",
    "fig.subplots_adjust(wspace=0.3)\n",
    "fig.savefig(\"output/rmse_bar_plots_all_systems.png\", dpi=300, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = get_subplots(systems)\n",
    "\n",
    "DATASET = \"standard\"\n",
    "\n",
    "# For MIF only, plot the RMSE for each dataset with a bar plot on a new axis.\n",
    "for i, system in enumerate(systems):\n",
    "    ax = axs[i]\n",
    "    rmse = [overall_results[DATASET][system][method][\"rmse\"] for method in fixed_methods]\n",
    "    cis = [overall_results[DATASET][system][method][\"rmse_ci\"] for method in fixed_methods]\n",
    "\n",
    "    # Convert CIs from absolute values to relative values\n",
    "    cis_lower = abs(np.array(cis)[:,0] - np.array(rmse))\n",
    "    cis_upper = abs(np.array(cis)[:,1] - np.array(rmse))\n",
    "    ax.bar(fixed_methods, rmse, yerr=[cis_lower, cis_upper], capsize=5, alpha=0.7, label=system)\n",
    "\n",
    "    # Rotate labels 90 degrees\n",
    "    ax.set_xticklabels(fixed_methods, rotation=90)\n",
    "    ax.set_ylabel(\"RMSE / kcal mol$^{-1}$\")\n",
    "    ax.set_title(system)\n",
    "\n",
    "    # Get the lowest RMSE from any fixed-time method\n",
    "    fixed_rmse = [overall_results[DATASET][system][method][\"rmse\"] for method in fixed_methods]\n",
    "    # Get the name of the lowest RMSE method\n",
    "    best_fixed_method = fixed_methods[np.argmin(fixed_rmse)]\n",
    "    ax.axhline(min(fixed_rmse), color=\"red\", linestyle=\"--\")\n",
    "    # Add text with the best fixed-time method\n",
    "    # ax.text(0.5, min(fixed_rmse), f\"Best fixed-time method: {best_fixed_method}\", ha=\"center\", va=\"bottom\")\n",
    "    \n",
    "\n",
    "    # Remove x labels from first 3 plots\n",
    "    if i < 3:\n",
    "        ax.set_xticklabels([])\n",
    "\n",
    "    # Remove y labels from right column\n",
    "    if i % 2 == 1:\n",
    "        ax.set_ylabel(\"\")\n",
    "\n",
    "# Stop the long labels overlapping\n",
    "fig.subplots_adjust(wspace=0.3)\n",
    "fig.savefig(\"output/rmse_bar_plots_all_systems_fixed_methods.png\", dpi=300, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the distributions of frac_discarded for each system for the \"standard\" dataset\n",
    "# Use seaborn to plot the distributions\n",
    "\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "DATASET  = \"standard\"\n",
    "\n",
    "fig, axs = get_subplots(systems)\n",
    "\n",
    "for i, system in enumerate(systems):\n",
    "    ax = axs[i]\n",
    "    df_means = pd.DataFrame({method: distributions[DATASET][system][method][\"fracs\"] for method in automated_methods})\n",
    "    sns.violinplot(data=df_means, ax=ax)\n",
    "    ax.set_title(system)\n",
    "    ax.set_ylabel(\"Fraction of data discarded\")\n",
    "    ax.set_xticklabels(methods, rotation=90)\n",
    "\n",
    "    # Figure out the optimal (lowest RMSE) fixed truncation time and draw a horizontal line\n",
    "    fixed_rmse = [overall_results[DATASET][system][method][\"rmse\"] for method in fixed_methods]\n",
    "    best_fixed_method = fixed_methods[np.argmin(fixed_rmse[:-1])]\n",
    "    best_fixed_time = float(best_fixed_method.split(\" \")[-1])\n",
    "    ax.axhline(best_fixed_time, color=\"red\", linestyle=\"--\")\n",
    "    \n",
    "    # Remove x labels from first 3 plots\n",
    "    if i < 3:\n",
    "        ax.set_xticklabels([])\n",
    "\n",
    "    # Remove y labels from right column\n",
    "    if i % 2 == 1:\n",
    "        ax.set_ylabel(\"\")\n",
    "\n",
    "# Stop the long labels overlapping\n",
    "fig.subplots_adjust(wspace=0.3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot distributions of RMSEs\n",
    "fig, axs = get_subplots(systems)\n",
    "\n",
    "for i, system in enumerate(systems):\n",
    "    ax = axs[i]\n",
    "    df_means = pd.DataFrame({method: distributions[\"standard\"][system][method][\"mses\"] for method in automated_methods})\n",
    "    sns.violinplot(data=df_means, ax=ax)\n",
    "    ax.set_title(system)\n",
    "    ax.set_ylabel(\"Mean / kcal mol$^{-1}$\")\n",
    "    ax.set_xticklabels(methods, rotation=90)\n",
    "\n",
    "    # Figure out the optimal (lowest RMSE) fixed truncation time and draw a horizontal line\n",
    "    fixed_rmse = [overall_results[\"standard\"][system][method][\"mue\"] for method in fixed_methods]\n",
    "    best_fixed_method = fixed_methods[np.argmin(fixed_rmse[:-1])]\n",
    "    best_fixed_time = float(best_fixed_method.split(\" \")[-1])\n",
    "    ax.axhline(best_fixed_time, color=\"red\", linestyle=\"--\")\n",
    "    \n",
    "    # Remove x labels from first 3 plots\n",
    "    if i < 3:\n",
    "        ax.set_xticklabels([])\n",
    "\n",
    "    # Remove y labels from right column\n",
    "    if i % 2 == 1:\n",
    "        ax.set_ylabel(\"\")\n",
    "\n",
    "# Stop the long labels overlapping\n",
    "fig.subplots_adjust(wspace=0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot distributions of RMSEs\n",
    "fig, axs = get_subplots(systems)\n",
    "\n",
    "for i, system in enumerate(systems):\n",
    "    ax = axs[i]\n",
    "    df_means = pd.DataFrame({method: distributions[\"standard\"][system][method][\"means\"] for method in methods})\n",
    "    sns.violinplot(data=df_means, ax=ax)\n",
    "    ax.set_title(system)\n",
    "    ax.set_ylabel(\"Mean / kcal mol$^{-1}$\")\n",
    "    ax.set_xticklabels(methods, rotation=90)\n",
    "\n",
    "    # Figure out the optimal (lowest RMSE) fixed truncation time and draw a horizontal line\n",
    "    fixed_rmse = [overall_results[\"standard\"][system][method][\"mue\"] for method in fixed_methods]\n",
    "    best_fixed_method = fixed_methods[np.argmin(fixed_rmse[:-1])]\n",
    "    best_fixed_time = float(best_fixed_method.split(\" \")[-1])\n",
    "    ax.axhline(best_fixed_time, color=\"red\", linestyle=\"--\")\n",
    "    \n",
    "    # Remove x labels from first 3 plots\n",
    "    if i < 3:\n",
    "        ax.set_xticklabels([])\n",
    "\n",
    "    # Remove y labels from right column\n",
    "    if i % 2 == 1:\n",
    "        ax.set_ylabel(\"\")\n",
    "\n",
    "# Stop the long labels overlapping\n",
    "fig.subplots_adjust(wspace=0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot distributions of RMSEs\n",
    "fig, axs = get_subplots(systems)\n",
    "\n",
    "for i, system in enumerate(systems):\n",
    "    ax = axs[i]\n",
    "    df_means = pd.DataFrame({method: distributions[\"standard\"][system][method][\"mues\"] for method in automated_methods})\n",
    "    sns.violinplot(data=df_means, ax=ax)\n",
    "    ax.set_title(system)\n",
    "    ax.set_ylabel(\"MUE / kcal mol$^{-1}$\")\n",
    "    ax.set_xticklabels(methods, rotation=90)\n",
    "\n",
    "    # Figure out the optimal (lowest RMSE) fixed truncation time and draw a horizontal line\n",
    "    fixed_rmse = [overall_results[\"standard\"][system][method][\"mue\"] for method in fixed_methods]\n",
    "    best_fixed_method = fixed_methods[np.argmin(fixed_rmse[:-1])]\n",
    "    best_fixed_time = float(best_fixed_method.split(\" \")[-1])\n",
    "    ax.axhline(best_fixed_time, color=\"red\", linestyle=\"--\")\n",
    "    \n",
    "    # Remove x labels from first 3 plots\n",
    "    if i < 3:\n",
    "        ax.set_xticklabels([])\n",
    "\n",
    "    # Remove y labels from right column\n",
    "    if i % 2 == 1:\n",
    "        ax.set_ylabel(\"\")\n",
    "\n",
    "# Stop the long labels overlapping\n",
    "fig.subplots_adjust(wspace=0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_rmse = [overall_results[\"standard\"][system][method][\"rmse\"] for method in fixed_methods]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, dataset in enumerate(datasets):\n",
    "    ax = axs[i]\n",
    "    rmse = [overall_results[dataset][\"MDM2-PIP2\"][method][\"rmse\"] for method in automated_methods]\n",
    "    cis = [overall_results[dataset][\"MDM2-PIP2\"][method][\"rmse_ci\"] for method in automated_methods]\n",
    "    # Convert CIs from absolute values to relative values\n",
    "    cis_lower = abs(np.array(cis)[:,0] - np.array(rmse))\n",
    "    cis_upper = abs(np.array(cis)[:,1] - np.array(rmse))\n",
    "    ax.bar(automated_methods, rmse, yerr=[cis_lower, cis_upper], capsize=5)\n",
    "    # Rotate labels 90 degrees\n",
    "    ax.set_xticklabels(methods, rotation=90)\n",
    "    ax.set_ylabel(\"RMSE\")\n",
    "    ax.set_title(dataset)\n",
    "\n",
    "fig.tight_layout()\n",
    "# Stop the long labels overlapping\n",
    "# fig.subplots_adjust(hspace=1.5, wspace=0.3)\n",
    "fig.savefig(\"output/rmse_bar_plots.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cis_upper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute bias and variance\n",
    "overall_results = {}\n",
    "distributions = {}\n",
    "\n",
    "for method in methods:\n",
    "    means = [data[i][method][\"mean\"] for i in synthetic_data_8_ns]\n",
    "    bias = np.mean(means) \n",
    "    variance = np.var(means)\n",
    "    # Get the overall mean absolute error\n",
    "    maes = np.abs(means)\n",
    "    mae = np.mean(maes)\n",
    "    mses = np.square(means)\n",
    "    rmse = np.sqrt(np.mean(mses))\n",
    "    # Time taken\n",
    "    #times = [synthetic_data_8_ns[i][method][\"time\"] for i in synthetic_data_8_ns]\n",
    "    #time_taken = np.mean(times)\n",
    "    # Frac discarded\n",
    "    fracs = [synthetic_data_8_ns[i][method][\"frac_discarded\"] for i in synthetic_data_8_ns]\n",
    "    frac_discarded = np.mean(fracs)\n",
    "    overall_results[method] = {\"bias\": bias, \"variance\": variance, \"mae\": mae, \"rmse\": rmse, \"frac_discarded\": frac_discarded}\n",
    "    distributions[method] = {\"means\": means, \"fracs\": fracs, \"maes\": maes, \"mses\": mses}\n",
    "\n",
    "# Get the 95 % confidence interval for the mean for each of the properties above\n",
    "for method in tqdm.tqdm(methods):\n",
    "    # Get the 95 % confidence interval for the mean\n",
    "    mean_ci, mean_distr = bootstrap(distributions[method][\"means\"])\n",
    "    frac_ci, frac_distr = bootstrap(distributions[method][\"fracs\"])\n",
    "    # Get the 95 % confidence interval for the variance, mae, rmse, and bias\n",
    "    var_ci, var_distr = bootstrap(distributions[method][\"means\"], np.var)\n",
    "    mae_ci, mae_distr = bootstrap(distributions[method][\"means\"], lambda x: np.abs(x))\n",
    "    rmse_ci, rmse_distr = bootstrap(distributions[method][\"means\"], lambda x: np.square(x))\n",
    "    # Sqrt things to get proper rmse\n",
    "    rmse_ci = np.sqrt(rmse_ci)\n",
    "    rmse_distr = np.sqrt(rmse_distr)\n",
    "    overall_results[method][\"bias_ci\"] = [abs(val - overall_results[method][\"bias\"]) for val in mean_ci]\n",
    "    overall_results[method][\"frac_ci\"] = [abs(val - overall_results[method][\"frac_discarded\"]) for val in frac_ci]\n",
    "    overall_results[method][\"var_ci\"] = [abs(val - overall_results[method][\"variance\"]) for val in var_ci]\n",
    "    overall_results[method][\"mae_ci\"] = [abs(val - overall_results[method][\"mae\"]) for val in mae_ci]\n",
    "    overall_results[method][\"rmse_ci\"] = [abs(val - overall_results[method][\"rmse\"]) for val in rmse_ci]\n",
    "    # Add the distributions\n",
    "    distributions[method][\"bias_distr\"] = mean_distr\n",
    "    distributions[method][\"frac_distr\"] = frac_distr\n",
    "    distributions[method][\"var_distr\"] = var_distr\n",
    "    distributions[method][\"mae_distr\"] = mae_distr\n",
    "    distributions[method][\"rmse_distr\"] = rmse_distr\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "red_reproduce",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
